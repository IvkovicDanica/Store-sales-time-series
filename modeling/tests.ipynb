{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c50ec1ef",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-07-14T09:43:26.058586Z",
     "iopub.status.busy": "2023-07-14T09:43:26.058180Z",
     "iopub.status.idle": "2023-07-14T09:43:52.019737Z",
     "shell.execute_reply": "2023-07-14T09:43:52.017974Z"
    },
    "papermill": {
     "duration": 25.991775,
     "end_time": "2023-07-14T09:43:52.022351",
     "exception": false,
     "start_time": "2023-07-14T09:43:26.030576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "                        \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.dataprocessing.transformers import Scaler, InvertibleMapper, StaticCovariatesTransformer\n",
    "from darts.dataprocessing.transformers.missing_values_filler import MissingValuesFiller\n",
    "from darts.models import LinearRegressionModel, LightGBMModel, XGBModel, CatBoostModel\n",
    "from darts.models.filtering.moving_average_filter import MovingAverageFilter\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "COLORS = list(sns.color_palette())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d20c171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:43:52.179396Z",
     "iopub.status.busy": "2023-07-14T09:43:52.179012Z",
     "iopub.status.idle": "2023-07-14T09:43:52.184564Z",
     "shell.execute_reply": "2023-07-14T09:43:52.183469Z"
    },
    "papermill": {
     "duration": 0.034554,
     "end_time": "2023-07-14T09:43:52.186557",
     "exception": false,
     "start_time": "2023-07-14T09:43:52.152003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to print messages\n",
    "def cprint(title, *args):\n",
    "    print(\n",
    "        \"=\"*len(title), title, \"=\"*len(title),\n",
    "        *args,\n",
    "        sep=\"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834352e5",
   "metadata": {
    "papermill": {
     "duration": 0.025298,
     "end_time": "2023-07-14T09:43:52.237216",
     "exception": false,
     "start_time": "2023-07-14T09:43:52.211918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f02402ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>transactions</th>\n",
       "      <th>...</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>season</th>\n",
       "      <th>wageday</th>\n",
       "      <th>day_to_nearest_holiday</th>\n",
       "      <th>day_from_nearest_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0       date    store_nbr      family  \\\n",
       "0             0             0           0 2013-01-01  store_nbr_1  AUTOMOTIVE   \n",
       "1             1             1           1 2013-01-01  store_nbr_1   BABY CARE   \n",
       "2             2             2           2 2013-01-01  store_nbr_1      BEAUTY   \n",
       "3             3             3           3 2013-01-01  store_nbr_1   BEVERAGES   \n",
       "4             4             4           4 2013-01-01  store_nbr_1       BOOKS   \n",
       "\n",
       "    id  sales  onpromotion  transactions  ...  is_month_start is_month_end  \\\n",
       "0  0.0    NaN          NaN           0.0  ...               1            0   \n",
       "1  1.0    NaN          NaN           0.0  ...               1            0   \n",
       "2  2.0    NaN          NaN           0.0  ...               1            0   \n",
       "3  3.0    NaN          NaN           0.0  ...               1            0   \n",
       "4  4.0    NaN          NaN           0.0  ...               1            0   \n",
       "\n",
       "  is_quarter_start is_quarter_end is_year_start  is_year_end  season  wageday  \\\n",
       "0                1              0             1            0       0        0   \n",
       "1                1              0             1            0       0        0   \n",
       "2                1              0             1            0       0        0   \n",
       "3                1              0             1            0       0        0   \n",
       "4                1              0             1            0       0        0   \n",
       "\n",
       "   day_to_nearest_holiday  day_from_nearest_holiday  \n",
       "0                       0                         0  \n",
       "1                       0                         0  \n",
       "2                       0                         0  \n",
       "3                       0                         0  \n",
       "4                       0                         0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('originalni_datasetovi/pre_validate.csv', parse_dates=['date'])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfed22ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:45:01.872635Z",
     "iopub.status.busy": "2023-07-14T09:45:01.872104Z",
     "iopub.status.idle": "2023-07-14T09:45:01.878734Z",
     "shell.execute_reply": "2023-07-14T09:45:01.877964Z"
    },
    "papermill": {
     "duration": 0.062944,
     "end_time": "2023-07-14T09:45:01.880493",
     "exception": false,
     "start_time": "2023-07-14T09:45:01.817549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pipeline(static_covs_transform=False, log_transform=False):\n",
    "    lst = []\n",
    "    \n",
    "    # fill missing values\n",
    "    filler = MissingValuesFiller(n_jobs=-1)\n",
    "    lst.append(filler)\n",
    "    \n",
    "    # specify transformation for static covariates\n",
    "    if static_covs_transform:\n",
    "        static_covs_transformer = StaticCovariatesTransformer(\n",
    "            transformer_cat=OneHotEncoder(),\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        lst.append(static_covs_transformer)\n",
    "\n",
    "    # perform log transformation on sales\n",
    "    if log_transform:\n",
    "        log_transformer = InvertibleMapper(\n",
    "            fn=np.log1p,\n",
    "            inverse_fn=np.expm1,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        lst.append(log_transformer)\n",
    "\n",
    "    # rescale time series\n",
    "    scaler = Scaler()\n",
    "    lst.append(scaler)\n",
    "\n",
    "    # chain all transformations\n",
    "    pipeline = Pipeline(lst)\n",
    "    return pipeline\n",
    "\n",
    "train_end = '2017-08-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471665f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:45:02.196836Z",
     "iopub.status.busy": "2023-07-14T09:45:02.196000Z",
     "iopub.status.idle": "2023-07-14T09:45:02.204473Z",
     "shell.execute_reply": "2023-07-14T09:45:02.203325Z"
    },
    "papermill": {
     "duration": 0.064891,
     "end_time": "2023-07-14T09:45:02.206840",
     "exception": false,
     "start_time": "2023-07-14T09:45:02.141949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_target_series(static_cols, log_transform=True):    \n",
    "    target_dict = {}\n",
    "    pipe_dict = {}\n",
    "    id_dict = {}\n",
    "\n",
    "    for fam in tqdm_notebook(data.family.unique(), desc=\"Extracting target series\"):\n",
    "        # filter data for each model\n",
    "        df = data[(data.family.eq(fam)) & (data.date.le(train_end))]\n",
    "        \n",
    "        # initialize transformation pipeline for target series\n",
    "        pipe = get_pipeline(True, log_transform=log_transform)\n",
    "        \n",
    "        # extract target series together with static covariates\n",
    "        target = TimeSeries.from_group_dataframe(\n",
    "            df=df,\n",
    "            time_col=\"date\",\n",
    "            value_cols=\"sales\",\n",
    "            group_cols=\"store_nbr\",\n",
    "            static_cols=static_cols,\n",
    "        )\n",
    "\n",
    "        # record identity of each target series\n",
    "        target_id = [{\"store_nbr\": t.static_covariates.store_nbr[0], \"family\": fam} \n",
    "                     for t in target]\n",
    "        id_dict[fam] = target_id\n",
    "        \n",
    "        # apply transformations\n",
    "        target = pipe.fit_transform(target)\n",
    "        target_dict[fam] = [t.astype(np.float32) for t in target]\n",
    "        pipe_dict[fam] = pipe[2:]\n",
    "        \n",
    "    return target_dict, pipe_dict, id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a71b0a90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:45:02.317491Z",
     "iopub.status.busy": "2023-07-14T09:45:02.316916Z",
     "iopub.status.idle": "2023-07-14T09:46:31.415239Z",
     "shell.execute_reply": "2023-07-14T09:46:31.414093Z"
    },
    "papermill": {
     "duration": 89.157455,
     "end_time": "2023-07-14T09:46:31.417699",
     "exception": false,
     "start_time": "2023-07-14T09:45:02.260244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0049877166748046875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting target series",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca7ba1fc4e74e0faa8abf4740225960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting target series:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# list of static covariates excluding 'store_nbr'; 'store_nbr' is automatically extracted using 'group_cols'\n",
    "static_cols = [\"city\", \"state\", \"type\", \"cluster\"]\n",
    "\n",
    "target_dict, pipe_dict, id_dict = get_target_series(static_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32bee58",
   "metadata": {
    "papermill": {
     "duration": 0.050822,
     "end_time": "2023-07-14T09:46:31.520930",
     "exception": false,
     "start_time": "2023-07-14T09:46:31.470108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Extracting the past and future covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d46fb39",
   "metadata": {
    "papermill": {
     "duration": 0.050653,
     "end_time": "2023-07-14T09:46:31.623179",
     "exception": false,
     "start_time": "2023-07-14T09:46:31.572526",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For past covariates, we only have the `transactions` column. For future covariates, we have the `oil`, `onpromotion` columns, the holiday columns, as well as the date-related columns. To improve our models, we can extract additional covariates by computing the moving averages of our time series data using `MovingAverageFilter`. Doing so helps to smooth out the noise and capture the underlying patterns more effectively.\n",
    "\n",
    "\\* *We follow the reference notebook to use moving averages of `oil` and `onpromotion` with window sizes 7, 28. The code below supports the computation of moving averages for only the past and future covariates. To include the moving averages of the target series `sales`, some edits are needed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91c27adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:46:31.728596Z",
     "iopub.status.busy": "2023-07-14T09:46:31.728255Z",
     "iopub.status.idle": "2023-07-14T09:46:31.740053Z",
     "shell.execute_reply": "2023-07-14T09:46:31.738887Z"
    },
    "papermill": {
     "duration": 0.067136,
     "end_time": "2023-07-14T09:46:31.742230",
     "exception": false,
     "start_time": "2023-07-14T09:46:31.675094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_covariates(\n",
    "    past_cols,\n",
    "    future_cols,\n",
    "    past_ma_cols=None,\n",
    "    future_ma_cols=None,\n",
    "    past_window_sizes=[7, 28],\n",
    "    future_window_sizes=[7, 28],\n",
    "):\n",
    "    past_dict = {}\n",
    "    future_dict = {}\n",
    "    \n",
    "    # initialize transformation pipeline for covariates\n",
    "    covs_pipe = get_pipeline()\n",
    "\n",
    "    for fam in tqdm_notebook(data.family.unique(), desc=\"Extracting covariates\"):\n",
    "        # filter data for each model\n",
    "        df = data[data.family.eq(fam)]\n",
    "        \n",
    "        # extract past covariates\n",
    "        past_covs = TimeSeries.from_group_dataframe(\n",
    "            df=df[df.date.le(train_end)],\n",
    "            time_col=\"date\",\n",
    "            value_cols=past_cols,\n",
    "            group_cols=\"store_nbr\",\n",
    "        )\n",
    "        past_covs = [p.with_static_covariates(None) for p in past_covs]\n",
    "        past_covs = covs_pipe.fit_transform(past_covs)\n",
    "        if past_ma_cols is not None:\n",
    "            for size in past_window_sizes:\n",
    "                ma_filter = MovingAverageFilter(window=size)\n",
    "                old_names = [f\"rolling_mean_{size}_{col}\" for col in past_ma_cols]\n",
    "                new_names = [f\"{col}_ma{size}\" for col in past_ma_cols]\n",
    "                past_ma_covs = [\n",
    "                    ma_filter.filter(p[past_ma_cols]).with_columns_renamed(old_names, new_names) \n",
    "                    for p in past_covs\n",
    "                ]\n",
    "                past_covs = [p.stack(p_ma) for p, p_ma in zip(past_covs, past_ma_covs)]\n",
    "        \n",
    "        past_dict[fam] = [p.astype(np.float32) for p in past_covs]\n",
    "\n",
    "        # extract future covariates\n",
    "        future_covs = TimeSeries.from_group_dataframe(\n",
    "            df=df,\n",
    "            time_col=\"date\",\n",
    "            value_cols=future_cols,\n",
    "            group_cols=\"store_nbr\",\n",
    "        )\n",
    "        future_covs = [f.with_static_covariates(None) for f in future_covs]\n",
    "        future_covs = covs_pipe.fit_transform(future_covs)\n",
    "        if future_ma_cols is not None:\n",
    "            for size in future_window_sizes:\n",
    "                ma_filter = MovingAverageFilter(window=size)\n",
    "                old_names = [f\"rolling_mean_{size}_{col}\" for col in future_ma_cols]\n",
    "                new_names = [f\"{col}_ma{size}\" for col in future_ma_cols]\n",
    "                future_ma_covs = [\n",
    "                    ma_filter.filter(f[future_ma_cols]).with_columns_renamed(old_names, new_names) \n",
    "                    for f in future_covs\n",
    "                ]\n",
    "                future_covs = [f.stack(f_ma) for f, f_ma in zip(future_covs, future_ma_covs)]\n",
    "        \n",
    "        future_dict[fam] = [f.astype(np.float32) for f in future_covs]\n",
    "            \n",
    "    return past_dict, future_dict\n",
    "\n",
    "selected_holidays = [\n",
    "    \"nat_terremoto\", \"nat_navidad\", \"nat_dia la madre\", \"nat_dia trabajo\",\n",
    "    \"nat_primer dia ano\", \"nat_futbol\", \"nat_dia difuntos\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70881fbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:46:31.848125Z",
     "iopub.status.busy": "2023-07-14T09:46:31.847089Z",
     "iopub.status.idle": "2023-07-14T09:48:00.040775Z",
     "shell.execute_reply": "2023-07-14T09:48:00.039203Z"
    },
    "papermill": {
     "duration": 88.248859,
     "end_time": "2023-07-14T09:48:00.042674",
     "exception": false,
     "start_time": "2023-07-14T09:46:31.793815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0.38067 sa svim\n",
    "# 0.37984 bez icega\n",
    "\n",
    "\n",
    "\n",
    "# past covariates\n",
    "past_cols = [\"transactions\"]\n",
    "\n",
    "# future covariates\n",
    "future_cols = [\n",
    "    \"oil\", \"onpromotion\",\n",
    "    \"day\", \"month\", \"year\", \"day_of_week\", \"day_of_year\", \"week_of_year\", \"date_index\",\n",
    "    \"work_day\", *selected_holidays,\n",
    "]\n",
    "\n",
    "holidays_to_add = ['N Batalla de Pichincha', 'N Carnaval', 'N Cyber Monday', 'N Independencia de Cuenca', 'N Independencia de Guayaquil', 'N Viernes Santo']\n",
    "\n",
    "for new_holiday in holidays_to_add:\n",
    "    future_cols.append(new_holiday)\n",
    "\n",
    "time_based_to_add = ['day_of_month', 'is_wknd', \n",
    "       'is_year_end', 'wageday', 'day_to_nearest_holiday', 'day_from_nearest_holiday', 'is_quarter_start', 'week_of_month',\n",
    "       'is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_start', 'is_month_end']\n",
    "\n",
    "izbaceni = ['is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_start', 'is_month_end']\n",
    "\n",
    "for time_based in time_based_to_add:\n",
    "    future_cols.append(time_based)\n",
    "\n",
    "# additional past and future covariates from computing the moving averages\n",
    "past_ma_cols = None\n",
    "future_ma_cols = [\"oil\", \"onpromotion\"]\n",
    "\n",
    "past_dict, future_dict = get_covariates(past_cols, future_cols, past_ma_cols, future_ma_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1e4ed",
   "metadata": {
    "papermill": {
     "duration": 0.05152,
     "end_time": "2023-07-14T09:48:00.145918",
     "exception": false,
     "start_time": "2023-07-14T09:48:00.094398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Setting up the model trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3142f781",
   "metadata": {
    "papermill": {
     "duration": 0.05115,
     "end_time": "2023-07-14T09:48:00.248274",
     "exception": false,
     "start_time": "2023-07-14T09:48:00.197124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We are now done with extracting the time series data for forecasting with Darts. The complete list of covariates is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84046e8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:48:00.569172Z",
     "iopub.status.busy": "2023-07-14T09:48:00.568840Z",
     "iopub.status.idle": "2023-07-14T09:48:00.574406Z",
     "shell.execute_reply": "2023-07-14T09:48:00.573225Z"
    },
    "papermill": {
     "duration": 0.059646,
     "end_time": "2023-07-14T09:48:00.576339",
     "exception": false,
     "start_time": "2023-07-14T09:48:00.516693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINER_CONFIG = {\n",
    "    # the time series data previously extracted\n",
    "    \"target_dict\": target_dict,\n",
    "    \"pipe_dict\": pipe_dict,\n",
    "    \"id_dict\": id_dict,\n",
    "    \"past_dict\": past_dict,\n",
    "    \"future_dict\": future_dict,\n",
    "    \n",
    "    # time series cross-validation using a rolling forecasting origin\n",
    "    \"forecast_horizon\": 16, # the length of the validation set\n",
    "    \"folds\": 1, # the number of training sets (setting to 1 means the standard train-validation split)\n",
    "    \n",
    "    # the number of previous days to check for zero sales; if all are zero, generate zero forecasts\n",
    "    \"zero_fc_window\": 21,\n",
    "    \n",
    "    # specify the covariates in a list to include in the model\n",
    "    # set to None to not use any, and set to 'keep_all' to include everything\n",
    "    \"static_covs\": \"keep_all\", # specify from ['city', 'state', 'cluster', 'type', 'store_nbr'], will extract all one-hot encoded columns\n",
    "    \"past_covs\": \"keep_all\",\n",
    "    \"future_covs\": \"keep_all\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8571e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:48:00.685550Z",
     "iopub.status.busy": "2023-07-14T09:48:00.685168Z",
     "iopub.status.idle": "2023-07-14T09:48:00.722555Z",
     "shell.execute_reply": "2023-07-14T09:48:00.721800Z"
    },
    "papermill": {
     "duration": 0.094091,
     "end_time": "2023-07-14T09:48:00.724637",
     "exception": false,
     "start_time": "2023-07-14T09:48:00.630546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_dict,\n",
    "        pipe_dict,\n",
    "        id_dict,\n",
    "        past_dict,\n",
    "        future_dict,\n",
    "        forecast_horizon,\n",
    "        folds,\n",
    "        zero_fc_window,\n",
    "        static_covs=None,\n",
    "        past_covs=None,\n",
    "        future_covs=None,\n",
    "    ):\n",
    "        self.target_dict = target_dict.copy()\n",
    "        self.pipe_dict = pipe_dict.copy()\n",
    "        self.id_dict = id_dict.copy()\n",
    "        self.past_dict = past_dict.copy()\n",
    "        self.future_dict = future_dict.copy()\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.folds = folds\n",
    "        self.zero_fc_window = zero_fc_window\n",
    "        self.static_covs = static_covs\n",
    "        self.past_covs = past_covs\n",
    "        self.future_covs = future_covs\n",
    "        \n",
    "        # set up time series data\n",
    "        self.setup()\n",
    "    \n",
    "    def setup(self):\n",
    "        for fam in tqdm_notebook(self.target_dict.keys(), desc=\"Setting up\"):\n",
    "            # keep the specified static covariates\n",
    "            if self.static_covs != \"keep_all\":\n",
    "                if self.static_covs is not None:\n",
    "                    target = self.target_dict[fam]\n",
    "                    keep_static = [col for col in target[0].static_covariates.columns if col.startswith(tuple(self.static_covs))]\n",
    "                    static_covs_df = [t.static_covariates[keep_static] for t in target]\n",
    "                    self.target_dict[fam] = [t.with_static_covariates(d) for t, d in zip(target, static_covs_df)]\n",
    "                else:\n",
    "                    self.target_dict[fam] = [t.with_static_covariates(None) for t in target]\n",
    "            \n",
    "            # keep the specified past covariates\n",
    "            if self.past_covs != \"keep_all\":\n",
    "                if self.past_covs is not None:\n",
    "                    self.past_dict[fam] = [p[self.past_covs] for p in self.past_dict[fam]]\n",
    "                else:\n",
    "                    self.past_dict[fam] = None\n",
    "                \n",
    "            # keep the specified future covariates\n",
    "            if self.future_covs != \"keep_all\":\n",
    "                if self.future_covs is not None:\n",
    "                    self.future_dict[fam] = [p[self.future_covs] for p in self.future_dict[fam]]\n",
    "                else:\n",
    "                    self.future_dict[fam] = None\n",
    "    \n",
    "    def clip(self, array):\n",
    "        return np.clip(array, a_min=0., a_max=None)\n",
    "    \n",
    "    def train_valid_split(self, target, length):\n",
    "        train = [t[:-length] for t in target]\n",
    "        valid_end_idx = -length + self.forecast_horizon\n",
    "        if valid_end_idx >= 0:\n",
    "            valid_end_idx = None\n",
    "        valid = [t[-length:valid_end_idx] for t in target]\n",
    "        \n",
    "        return train, valid\n",
    "    \n",
    "    def get_models(self, model_names, model_configs):\n",
    "        models = {\n",
    "            \"lr\": LinearRegressionModel,\n",
    "            \"lgbm\": LightGBMModel,\n",
    "            \"cat\": CatBoostModel,\n",
    "            \"xgb\": XGBModel,\n",
    "        }\n",
    "        assert isinstance(model_names, list) and isinstance(model_configs, list),\\\n",
    "        \"Both the model names and model configurations must be specified in lists.\"\n",
    "        assert all(name in models for name in model_names),\\\n",
    "        f\"Model names '{model_names}' not recognized.\"\n",
    "        assert len(model_names) == len(model_configs),\\\n",
    "        \"The number of model names and the number of model configurations do not match.\"\n",
    "        \n",
    "        if \"xgb\" in model_names:\n",
    "            xgb_idx = np.where(np.array(model_names)==\"xgb\")[0]\n",
    "            for idx in xgb_idx:\n",
    "                # change to histogram-based method for XGBoost to get faster training time\n",
    "                model_configs[idx] = {\"tree_method\": \"hist\", **model_configs[idx]}\n",
    "        \n",
    "        return [models[name](**model_configs[j]) for j, name in enumerate(model_names)]\n",
    "    \n",
    "    def generate_forecasts(self, models, train, pipe, past_covs, future_covs, drop_before):\n",
    "        if drop_before is not None:\n",
    "            date = pd.Timestamp(drop_before) - pd.Timedelta(days=1)\n",
    "            train = [t.drop_before(date) for t in train]\n",
    "        inputs = {\n",
    "            \"series\": train,\n",
    "            \"past_covariates\": past_covs,\n",
    "            \"future_covariates\": future_covs,\n",
    "        }\n",
    "        zero_pred = pd.DataFrame({\n",
    "            \"date\": pd.date_range(train[0].end_time(), periods=self.forecast_horizon+1)[1:],\n",
    "            \"sales\": np.zeros(self.forecast_horizon),\n",
    "        })\n",
    "        zero_pred = TimeSeries.from_dataframe(\n",
    "            df=zero_pred,\n",
    "            time_col=\"date\",\n",
    "            value_cols=\"sales\",\n",
    "        )\n",
    "        \n",
    "        pred_list = []\n",
    "        ens_pred = [0 for _ in range(len(train))]\n",
    "        \n",
    "        for m in models:\n",
    "            # fit training data to model\n",
    "            m.fit(**inputs)\n",
    "                \n",
    "            # generate forecasts and apply inverse transformations\n",
    "            pred = m.predict(n=self.forecast_horizon, **inputs, show_warnings=False)\n",
    "            \n",
    "            #print(m.feature_imprtance_)\n",
    "            pred = pipe.inverse_transform(pred)\n",
    "\n",
    "            # set zero forecasts for target series where the recent observations are 0s\n",
    "            for j in range(len(train)):\n",
    "                if train[j][-self.zero_fc_window:].values().sum() == 0:\n",
    "                    pred[j] = zero_pred\n",
    "            \n",
    "            # clip negative forecasts to 0s\n",
    "            pred = [p.map(self.clip) for p in pred]\n",
    "            pred_list.append(pred)\n",
    "            \n",
    "            # ensemble averaging\n",
    "            for j in range(len(ens_pred)):\n",
    "                ens_pred[j] += pred[j] / len(models)\n",
    "\n",
    "        return pred_list, ens_pred\n",
    "    \n",
    "    def metric(self, valid, pred):\n",
    "        valid_df = pd.concat([ts.pd_dataframe() for ts in valid], axis=1)\n",
    "        pred_df = pd.concat([ts.pd_dataframe() for ts in pred], axis=1)\n",
    "\n",
    "        # calculate RMSLE for each pair of valid and predicted values\n",
    "        rmsle_values = [mean_squared_log_error(valid_df[col], pred_df[col],squared=False) for col in valid_df.columns]\n",
    "\n",
    "        # calculate the mean of RMSLE values of all series of that family\n",
    "        mean_rmsle = np.mean(rmsle_values)\n",
    "\n",
    "        return mean_rmsle\n",
    "    \n",
    "    def validate(self, model_names, model_configs, drop_before=None):\n",
    "        # helper value to align printed text below\n",
    "        longest_len = len(max(self.target_dict.keys(), key=len))\n",
    "        \n",
    "        # store metric values for each model\n",
    "        model_metrics_history = []\n",
    "        ens_metric_history = []\n",
    "        \n",
    "        for fam in tqdm_notebook(self.target_dict, desc=\"Performing validation\"):\n",
    "            target = self.target_dict[fam]\n",
    "            pipe = self.pipe_dict[fam]\n",
    "            past_covs = self.past_dict[fam]\n",
    "            future_covs = self.future_dict[fam]\n",
    "            \n",
    "            # record average metric value over all folds\n",
    "            model_metrics = []\n",
    "            ens_metric = 0\n",
    "            \n",
    "            for j in range(self.folds):    \n",
    "                # perform train-validation split and apply transformations\n",
    "                length = (self.folds - j) * self.forecast_horizon\n",
    "                train, valid = self.train_valid_split(target, length)\n",
    "                valid = pipe.inverse_transform(valid)\n",
    "\n",
    "                # generate forecasts and compute metric\n",
    "                models = self.get_models(model_names, model_configs)\n",
    "                pred_list, ens_pred = self.generate_forecasts(models, train, pipe, past_covs, future_covs, drop_before)\n",
    "                metric_list = [self.metric(valid, pred) / self.folds for pred in pred_list]\n",
    "                model_metrics.append(metric_list)\n",
    "                if len(models) > 1:\n",
    "                    ens_metric_fold = self.metric(valid, ens_pred) / self.folds\n",
    "                    ens_metric += ens_metric_fold\n",
    "                \n",
    "            # store final metric value for each model\n",
    "            model_metrics = np.sum(model_metrics, axis=0)\n",
    "            model_metrics_history.append(model_metrics)\n",
    "            ens_metric_history.append(ens_metric)\n",
    "            \n",
    "            # print metric value for each family\n",
    "            print(\n",
    "                fam,\n",
    "                \" \" * (longest_len - len(fam)),\n",
    "                \" | \",\n",
    "                \" - \".join([f\"{model}: {metric:.5f}\" for model, metric in zip(model_names, model_metrics)]),\n",
    "                f\" - ens: {ens_metric:.5f}\" if len(models) > 1 else \"\",\n",
    "                sep=\"\",\n",
    "            )\n",
    "            \n",
    "        # print overall metric value\n",
    "        cprint(\n",
    "            \"Average RMSLE | \"\n",
    "            + \" - \".join([f\"{model}: {metric:.5f}\" \n",
    "                          for model, metric in zip(model_names, np.mean(model_metrics_history, axis=0))])\n",
    "            + (f\" - ens: {np.mean(ens_metric_history):.5f}\" if len(models) > 1 else \"\"),\n",
    "        )\n",
    "        \n",
    "    def ensemble_predict(self, model_names, model_configs, drop_before=None):        \n",
    "        forecasts = []\n",
    "        for fam in tqdm_notebook(self.target_dict.keys(), desc=\"Generating forecasts\"):\n",
    "            target = self.target_dict[fam]\n",
    "            pipe = self.pipe_dict[fam]\n",
    "            target_id = self.id_dict[fam]\n",
    "            past_covs = self.past_dict[fam]\n",
    "            future_covs = self.future_dict[fam]\n",
    "            \n",
    "            # generate forecasts\n",
    "            models = self.get_models(model_names, model_configs)\n",
    "            pred_list, ens_pred = self.generate_forecasts(models, target, pipe, past_covs, future_covs, drop_before)\n",
    "            ens_pred = [p.pd_dataframe().assign(**i) for p, i in zip(ens_pred, target_id)]\n",
    "            ens_pred = pd.concat(ens_pred, axis=0)\n",
    "            forecasts.append(ens_pred)\n",
    "            \n",
    "        # combine all forecasts into one dataframe\n",
    "        forecasts = pd.concat(forecasts, axis=0)\n",
    "        forecasts = forecasts.rename_axis(None, axis=1).reset_index(names=\"date\")\n",
    "        \n",
    "        return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cd9cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:48:00.830687Z",
     "iopub.status.busy": "2023-07-14T09:48:00.830178Z",
     "iopub.status.idle": "2023-07-14T09:48:00.846356Z",
     "shell.execute_reply": "2023-07-14T09:48:00.845192Z"
    },
    "papermill": {
     "duration": 0.070578,
     "end_time": "2023-07-14T09:48:00.848032",
     "exception": false,
     "start_time": "2023-07-14T09:48:00.777454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005985260009765625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Setting up",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bdb8e502dd6488babb465f0db72ded9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting up:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize model trainer\n",
    "trainer = Trainer(**TRAINER_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aef6be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizacija\n",
    "BASE_CONFIG = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 7,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "    \"n_estimators\": 300, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    \"max_depth\": -1, # -1\n",
    "    \"subsample\": 0.7,\n",
    "    \"alpha\": 0.9, # l1 0.9\n",
    "    \"reg_lambda\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0354a1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:48:01.391200Z",
     "iopub.status.busy": "2023-07-14T09:48:01.390349Z",
     "iopub.status.idle": "2023-07-14T09:49:48.437676Z",
     "shell.execute_reply": "2023-07-14T09:49:48.436696Z"
    },
    "papermill": {
     "duration": 107.104695,
     "end_time": "2023-07-14T09:49:48.440592",
     "exception": false,
     "start_time": "2023-07-14T09:48:01.335897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0049860477447509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Performing validation",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff74e1152f274166b4a3ec81c93ca630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lgbm: 0.49525\n",
      "BABY CARE                  | lgbm: 0.20741\n",
      "BEAUTY                     | lgbm: 0.48484\n",
      "BEVERAGES                  | lgbm: 0.23130\n",
      "BOOKS                      | lgbm: 0.05323\n",
      "BREAD/BAKERY               | lgbm: 0.17469\n",
      "CELEBRATION                | lgbm: 0.52287\n",
      "CLEANING                   | lgbm: 0.43663\n",
      "DAIRY                      | lgbm: 0.15432\n",
      "DELI                       | lgbm: 0.16311\n",
      "EGGS                       | lgbm: 0.26682\n",
      "FROZEN FOODS               | lgbm: 0.26591\n",
      "GROCERY I                  | lgbm: 0.17992\n",
      "GROCERY II                 | lgbm: 0.53606\n",
      "HARDWARE                   | lgbm: 0.52479\n",
      "HOME AND KITCHEN I         | lgbm: 0.49083\n",
      "HOME AND KITCHEN II        | lgbm: 0.44825\n",
      "HOME APPLIANCES            | lgbm: 0.31256\n",
      "HOME CARE                  | lgbm: 0.24478\n",
      "LADIESWEAR                 | lgbm: 0.42616\n",
      "LAWN AND GARDEN            | lgbm: 0.37309\n",
      "LINGERIE                   | lgbm: 0.62348\n",
      "LIQUOR,WINE,BEER           | lgbm: 0.47338\n",
      "MAGAZINES                  | lgbm: 0.50780\n",
      "MEATS                      | lgbm: 0.20783\n",
      "PERSONAL CARE              | lgbm: 0.24591\n",
      "PET SUPPLIES               | lgbm: 0.46470\n",
      "PLAYERS AND ELECTRONICS    | lgbm: 0.45509\n",
      "POULTRY                    | lgbm: 0.20484\n",
      "PREPARED FOODS             | lgbm: 0.27116\n",
      "PRODUCE                    | lgbm: 0.12930\n",
      "SCHOOL AND OFFICE SUPPLIES | lgbm: 0.54795\n",
      "SEAFOOD                    | lgbm: 0.45467\n",
      "=============================\n",
      "Average RMSLE | lgbm: 0.35088\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# 'lr' for linear regression\n",
    "trainer.validate([\"lgbm\"], [BASE_CONFIG], drop_before=\"2015-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "41d14556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005983591079711914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Performing validation",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c8f172764348e4a483a1dc80dc402d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lgbm: 0.49293\n",
      "BABY CARE                  | lgbm: 0.21119\n",
      "BEAUTY                     | lgbm: 0.44877\n",
      "BEVERAGES                  | lgbm: 0.20345\n",
      "BOOKS                      | lgbm: 0.06102\n",
      "BREAD/BAKERY               | lgbm: 0.16036\n",
      "CELEBRATION                | lgbm: 0.52644\n",
      "CLEANING                   | lgbm: 0.28581\n",
      "DAIRY                      | lgbm: 0.13659\n",
      "DELI                       | lgbm: 0.16829\n",
      "EGGS                       | lgbm: 0.25004\n",
      "FROZEN FOODS               | lgbm: 0.25336\n",
      "GROCERY I                  | lgbm: 0.14157\n",
      "GROCERY II                 | lgbm: 0.56561\n",
      "HARDWARE                   | lgbm: 0.52025\n",
      "HOME AND KITCHEN I         | lgbm: 0.49171\n",
      "HOME AND KITCHEN II        | lgbm: 0.42672\n",
      "HOME APPLIANCES            | lgbm: 0.29148\n",
      "HOME CARE                  | lgbm: 0.21383\n",
      "LADIESWEAR                 | lgbm: 0.40863\n",
      "LAWN AND GARDEN            | lgbm: 0.36433\n",
      "LINGERIE                   | lgbm: 0.62873\n",
      "LIQUOR,WINE,BEER           | lgbm: 0.39833\n",
      "MAGAZINES                  | lgbm: 0.49575\n",
      "MEATS                      | lgbm: 0.19227\n",
      "PERSONAL CARE              | lgbm: 0.21865\n",
      "PET SUPPLIES               | lgbm: 0.45837\n",
      "PLAYERS AND ELECTRONICS    | lgbm: 0.44213\n",
      "POULTRY                    | lgbm: 0.19495\n",
      "PREPARED FOODS             | lgbm: 0.25725\n",
      "PRODUCE                    | lgbm: 0.12536\n",
      "SCHOOL AND OFFICE SUPPLIES | lgbm: 0.56992\n",
      "SEAFOOD                    | lgbm: 0.45475\n",
      "=============================\n",
      "Average RMSLE | lgbm: 0.33512\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# Optimizacija\n",
    "BASE_CONFIG = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 63,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "    \"n_estimators\": 300, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "# 'lr' for linear regression\n",
    "trainer.validate([\"lgbm\"], [BASE_CONFIG], drop_before=\"2015-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "91e0d62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005984306335449219,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Performing validation",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3a2c808944414fb2826402a9df846f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lgbm: 0.49193\n",
      "BABY CARE                  | lgbm: 0.20948\n",
      "BEAUTY                     | lgbm: 0.46268\n",
      "BEVERAGES                  | lgbm: 0.20868\n",
      "BOOKS                      | lgbm: 0.05638\n",
      "BREAD/BAKERY               | lgbm: 0.16426\n",
      "CELEBRATION                | lgbm: 0.51965\n",
      "CLEANING                   | lgbm: 0.31911\n",
      "DAIRY                      | lgbm: 0.12816\n",
      "DELI                       | lgbm: 0.16199\n",
      "EGGS                       | lgbm: 0.25156\n",
      "FROZEN FOODS               | lgbm: 0.25086\n",
      "GROCERY I                  | lgbm: 0.14100\n",
      "GROCERY II                 | lgbm: 0.53296\n",
      "HARDWARE                   | lgbm: 0.51816\n",
      "HOME AND KITCHEN I         | lgbm: 0.47246\n",
      "HOME AND KITCHEN II        | lgbm: 0.42236\n",
      "HOME APPLIANCES            | lgbm: 0.28811\n",
      "HOME CARE                  | lgbm: 0.19006\n",
      "LADIESWEAR                 | lgbm: 0.41226\n",
      "LAWN AND GARDEN            | lgbm: 0.39436\n",
      "LINGERIE                   | lgbm: 0.62238\n",
      "LIQUOR,WINE,BEER           | lgbm: 0.41207\n",
      "MAGAZINES                  | lgbm: 0.49761\n",
      "MEATS                      | lgbm: 0.18939\n",
      "PERSONAL CARE              | lgbm: 0.22066\n",
      "PET SUPPLIES               | lgbm: 0.45500\n",
      "PLAYERS AND ELECTRONICS    | lgbm: 0.44470\n",
      "POULTRY                    | lgbm: 0.18423\n",
      "PREPARED FOODS             | lgbm: 0.25977\n",
      "PRODUCE                    | lgbm: 0.12437\n",
      "SCHOOL AND OFFICE SUPPLIES | lgbm: 0.57520\n",
      "SEAFOOD                    | lgbm: 0.46157\n",
      "=============================\n",
      "Average RMSLE | lgbm: 0.33465\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# Optimizacija\n",
    "BASE_CONFIG = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 365,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "    \"n_estimators\": 200, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "# 'lr' for linear regression\n",
    "trainer.validate([\"lgbm\"], [BASE_CONFIG], drop_before=\"2015-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2051f3fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0049860477447509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Performing validation",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b30733d5794061a763fd08a47f61bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lgbm: 0.49571\n",
      "BABY CARE                  | lgbm: 0.20934\n",
      "BEAUTY                     | lgbm: 0.46487\n",
      "BEVERAGES                  | lgbm: 0.21054\n",
      "BOOKS                      | lgbm: 0.06738\n",
      "BREAD/BAKERY               | lgbm: 0.16465\n",
      "CELEBRATION                | lgbm: 0.52257\n",
      "CLEANING                   | lgbm: 0.35189\n",
      "DAIRY                      | lgbm: 0.15258\n",
      "DELI                       | lgbm: 0.16671\n",
      "EGGS                       | lgbm: 0.26439\n",
      "FROZEN FOODS               | lgbm: 0.26325\n",
      "GROCERY I                  | lgbm: 0.16817\n",
      "GROCERY II                 | lgbm: 0.57830\n",
      "HARDWARE                   | lgbm: 0.52989\n",
      "HOME AND KITCHEN I         | lgbm: 0.48423\n",
      "HOME AND KITCHEN II        | lgbm: 0.43698\n",
      "HOME APPLIANCES            | lgbm: 0.27383\n",
      "HOME CARE                  | lgbm: 0.23687\n",
      "LADIESWEAR                 | lgbm: 0.41509\n",
      "LAWN AND GARDEN            | lgbm: 0.36476\n",
      "LINGERIE                   | lgbm: 0.63196\n",
      "LIQUOR,WINE,BEER           | lgbm: 0.44284\n",
      "MAGAZINES                  | lgbm: 0.50631\n",
      "MEATS                      | lgbm: 0.20528\n",
      "PERSONAL CARE              | lgbm: 0.24474\n",
      "PET SUPPLIES               | lgbm: 0.46466\n",
      "PLAYERS AND ELECTRONICS    | lgbm: 0.44884\n",
      "POULTRY                    | lgbm: 0.20875\n",
      "PREPARED FOODS             | lgbm: 0.26013\n",
      "PRODUCE                    | lgbm: 0.13413\n",
      "SCHOOL AND OFFICE SUPPLIES | lgbm: 0.56863\n",
      "SEAFOOD                    | lgbm: 0.45522\n",
      "=============================\n",
      "Average RMSLE | lgbm: 0.34526\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# Optimizacija\n",
    "BASE_CONFIG = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 14,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "    \"n_estimators\": 150, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "# 'lr' for linear regression\n",
    "trainer.validate([\"lgbm\"], [BASE_CONFIG], drop_before=\"2015-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "88fa18af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004985809326171875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Performing validation",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771c9a7702d94123b6fa72139bcaf101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lgbm: 0.49028\n",
      "BABY CARE                  | lgbm: 0.20723\n",
      "BEAUTY                     | lgbm: 0.44933\n",
      "BEVERAGES                  | lgbm: 0.21386\n",
      "BOOKS                      | lgbm: 0.06088\n",
      "BREAD/BAKERY               | lgbm: 0.15873\n",
      "CELEBRATION                | lgbm: 0.52122\n",
      "CLEANING                   | lgbm: 0.28049\n",
      "DAIRY                      | lgbm: 0.13595\n",
      "DELI                       | lgbm: 0.16695\n",
      "EGGS                       | lgbm: 0.25060\n",
      "FROZEN FOODS               | lgbm: 0.25231\n",
      "GROCERY I                  | lgbm: 0.14292\n",
      "GROCERY II                 | lgbm: 0.54803\n",
      "HARDWARE                   | lgbm: 0.51747\n",
      "HOME AND KITCHEN I         | lgbm: 0.48980\n",
      "HOME AND KITCHEN II        | lgbm: 0.43297\n",
      "HOME APPLIANCES            | lgbm: 0.28921\n",
      "HOME CARE                  | lgbm: 0.21222\n",
      "LADIESWEAR                 | lgbm: 0.41669\n",
      "LAWN AND GARDEN            | lgbm: 0.38105\n",
      "LINGERIE                   | lgbm: 0.62556\n",
      "LIQUOR,WINE,BEER           | lgbm: 0.39990\n",
      "MAGAZINES                  | lgbm: 0.49539\n",
      "MEATS                      | lgbm: 0.18781\n",
      "PERSONAL CARE              | lgbm: 0.21235\n",
      "PET SUPPLIES               | lgbm: 0.45609\n",
      "PLAYERS AND ELECTRONICS    | lgbm: 0.44081\n",
      "POULTRY                    | lgbm: 0.19057\n",
      "PREPARED FOODS             | lgbm: 0.25958\n",
      "PRODUCE                    | lgbm: 0.12435\n",
      "SCHOOL AND OFFICE SUPPLIES | lgbm: 0.58223\n",
      "SEAFOOD                    | lgbm: 0.45119\n",
      "=============================\n",
      "Average RMSLE | lgbm: 0.33467\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# Optimizacija\n",
    "BASE_CONFIG = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 120,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "    \"n_estimators\": 300, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "# 'lr' for linear regression\n",
    "trainer.validate([\"lgbm\"], [BASE_CONFIG], drop_before=\"2015-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15cd21e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0059833526611328125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Performing validation",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8254beaef09e42faae4b468987567b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lgbm: 0.50368\n",
      "BABY CARE                  | lgbm: 0.20253\n",
      "BEAUTY                     | lgbm: 0.46733\n",
      "BEVERAGES                  | lgbm: 0.21781\n",
      "BOOKS                      | lgbm: 0.04729\n",
      "BREAD/BAKERY               | lgbm: 0.17144\n",
      "CELEBRATION                | lgbm: 0.52002\n",
      "CLEANING                   | lgbm: 0.31361\n",
      "DAIRY                      | lgbm: 0.14556\n",
      "DELI                       | lgbm: 0.17737\n",
      "EGGS                       | lgbm: 0.26923\n",
      "FROZEN FOODS               | lgbm: 0.26359\n",
      "GROCERY I                  | lgbm: 0.15560\n",
      "GROCERY II                 | lgbm: 0.55569\n",
      "HARDWARE                   | lgbm: 0.51269\n",
      "HOME AND KITCHEN I         | lgbm: 0.48498\n",
      "HOME AND KITCHEN II        | lgbm: 0.42932\n",
      "HOME APPLIANCES            | lgbm: 0.32267\n",
      "HOME CARE                  | lgbm: 0.19316\n",
      "LADIESWEAR                 | lgbm: 0.42013\n",
      "LAWN AND GARDEN            | lgbm: 0.40750\n",
      "LINGERIE                   | lgbm: 0.63060\n",
      "LIQUOR,WINE,BEER           | lgbm: 0.40926\n",
      "MAGAZINES                  | lgbm: 0.50136\n",
      "MEATS                      | lgbm: 0.19446\n",
      "PERSONAL CARE              | lgbm: 0.22334\n",
      "PET SUPPLIES               | lgbm: 0.44902\n",
      "PLAYERS AND ELECTRONICS    | lgbm: 0.44885\n",
      "POULTRY                    | lgbm: 0.19157\n",
      "PREPARED FOODS             | lgbm: 0.26242\n",
      "PRODUCE                    | lgbm: 0.13841\n",
      "SCHOOL AND OFFICE SUPPLIES | lgbm: 0.56654\n",
      "SEAFOOD                    | lgbm: 0.47186\n",
      "=============================\n",
      "Average RMSLE | lgbm: 0.34148\n",
      "=============================\n"
     ]
    }
   ],
   "source": [
    "# Optimizacija\n",
    "BASE_CONFIG = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 730,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "    \"n_estimators\": 150, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "# 'lr' for linear regression\n",
    "trainer.validate([\"lgbm\"], [BASE_CONFIG], drop_before=\"2015-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200cb324",
   "metadata": {
    "papermill": {
     "duration": 0.055746,
     "end_time": "2023-07-14T09:49:48.551909",
     "exception": false,
     "start_time": "2023-07-14T09:49:48.496163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### LightGBM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4f497",
   "metadata": {
    "papermill": {
     "duration": 0.056372,
     "end_time": "2023-07-14T09:49:48.663510",
     "exception": false,
     "start_time": "2023-07-14T09:49:48.607138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We now use gradient-boosting decision tree (GBDT) models for actual forecasting. Some state-of-the-art options include LightGBM, XGBoost and CatBoost. We only focus on LightGBM because it appears to have faster training time. Additional hyperparameters can be specified but for simplicity, we use the default values. To stabilize performance, we perform ensemble averaging by training multiple models and aggregating the forecasts through averaging. This helps to average out the errors.\n",
    "\n",
    "\\* *We adopt the approach taken in the reference notebook to use different numbers of lags of the target series for each model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eea71c8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T09:49:48.776525Z",
     "iopub.status.busy": "2023-07-14T09:49:48.776157Z",
     "iopub.status.idle": "2023-07-14T09:49:48.781396Z",
     "shell.execute_reply": "2023-07-14T09:49:48.780584Z"
    },
    "papermill": {
     "duration": 0.06492,
     "end_time": "2023-07-14T09:49:48.783801",
     "exception": false,
     "start_time": "2023-07-14T09:49:48.718881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GBDT_CONFIG1 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 120,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 300, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "GBDT_CONFIG2 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 14,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 150, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG3 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 365,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 200, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG4 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 730,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 100, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "# 'lgbm' for LightGBM, 'xgb' for XGBoost, 'cat' for CatBoost\n",
    "ENS_MODELS = [\"lgbm\", \"lgbm\", \"lgbm\", \"lgbm\"]\n",
    "ENS_CONFIGS = [GBDT_CONFIG1, GBDT_CONFIG2, GBDT_CONFIG3, GBDT_CONFIG4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77517dd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T10:15:16.965775Z",
     "iopub.status.busy": "2023-07-14T10:15:16.965406Z",
     "iopub.status.idle": "2023-07-14T11:26:44.859001Z",
     "shell.execute_reply": "2023-07-14T11:26:44.857465Z"
    },
    "papermill": {
     "duration": 4287.995658,
     "end_time": "2023-07-14T11:26:44.901888",
     "exception": false,
     "start_time": "2023-07-14T10:15:16.906230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013962745666503906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Performing validation",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b302dc48f9aa4bcc95ceaeea9e2d0372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lgbm: 0.49028 - lgbm: 0.49571 - lgbm: 0.49193 - lgbm: 0.50219 - ens: 0.48910\n",
      "BABY CARE                  | lgbm: 0.20723 - lgbm: 0.20934 - lgbm: 0.20948 - lgbm: 0.20212 - ens: 0.20572\n",
      "BEAUTY                     | lgbm: 0.44933 - lgbm: 0.46487 - lgbm: 0.46268 - lgbm: 0.47157 - ens: 0.45610\n",
      "BEVERAGES                  | lgbm: 0.21386 - lgbm: 0.21054 - lgbm: 0.20868 - lgbm: 0.22421 - ens: 0.20709\n",
      "BOOKS                      | lgbm: 0.06088 - lgbm: 0.06738 - lgbm: 0.05638 - lgbm: 0.04706 - ens: 0.05787\n",
      "BREAD/BAKERY               | lgbm: 0.15873 - lgbm: 0.16465 - lgbm: 0.16426 - lgbm: 0.17364 - ens: 0.15984\n",
      "CELEBRATION                | lgbm: 0.52122 - lgbm: 0.52257 - lgbm: 0.51965 - lgbm: 0.51700 - ens: 0.51408\n",
      "CLEANING                   | lgbm: 0.28049 - lgbm: 0.35189 - lgbm: 0.31911 - lgbm: 0.30148 - ens: 0.30655\n",
      "DAIRY                      | lgbm: 0.13595 - lgbm: 0.15258 - lgbm: 0.12816 - lgbm: 0.14865 - ens: 0.13571\n",
      "DELI                       | lgbm: 0.16695 - lgbm: 0.16671 - lgbm: 0.16199 - lgbm: 0.17921 - ens: 0.16289\n",
      "EGGS                       | lgbm: 0.25060 - lgbm: 0.26439 - lgbm: 0.25156 - lgbm: 0.26942 - ens: 0.25098\n",
      "FROZEN FOODS               | lgbm: 0.25231 - lgbm: 0.26325 - lgbm: 0.25086 - lgbm: 0.26820 - ens: 0.25008\n",
      "GROCERY I                  | lgbm: 0.14292 - lgbm: 0.16817 - lgbm: 0.14100 - lgbm: 0.15934 - ens: 0.14355\n",
      "GROCERY II                 | lgbm: 0.54803 - lgbm: 0.57830 - lgbm: 0.53296 - lgbm: 0.54925 - ens: 0.54592\n",
      "HARDWARE                   | lgbm: 0.51747 - lgbm: 0.52989 - lgbm: 0.51816 - lgbm: 0.51241 - ens: 0.51528\n",
      "HOME AND KITCHEN I         | lgbm: 0.48980 - lgbm: 0.48423 - lgbm: 0.47246 - lgbm: 0.48202 - ens: 0.47499\n",
      "HOME AND KITCHEN II        | lgbm: 0.43297 - lgbm: 0.43698 - lgbm: 0.42236 - lgbm: 0.42977 - ens: 0.42409\n",
      "HOME APPLIANCES            | lgbm: 0.28921 - lgbm: 0.27383 - lgbm: 0.28811 - lgbm: 0.32549 - ens: 0.29151\n",
      "HOME CARE                  | lgbm: 0.21222 - lgbm: 0.23687 - lgbm: 0.19006 - lgbm: 0.19338 - ens: 0.19919\n",
      "LADIESWEAR                 | lgbm: 0.41669 - lgbm: 0.41509 - lgbm: 0.41226 - lgbm: 0.42588 - ens: 0.41140\n",
      "LAWN AND GARDEN            | lgbm: 0.38105 - lgbm: 0.36476 - lgbm: 0.39436 - lgbm: 0.39704 - ens: 0.37982\n",
      "LINGERIE                   | lgbm: 0.62556 - lgbm: 0.63196 - lgbm: 0.62238 - lgbm: 0.62423 - ens: 0.61887\n",
      "LIQUOR,WINE,BEER           | lgbm: 0.39990 - lgbm: 0.44284 - lgbm: 0.41207 - lgbm: 0.41285 - ens: 0.40304\n",
      "MAGAZINES                  | lgbm: 0.49539 - lgbm: 0.50631 - lgbm: 0.49761 - lgbm: 0.49606 - ens: 0.49253\n",
      "MEATS                      | lgbm: 0.18781 - lgbm: 0.20528 - lgbm: 0.18939 - lgbm: 0.19646 - ens: 0.18809\n",
      "PERSONAL CARE              | lgbm: 0.21235 - lgbm: 0.24474 - lgbm: 0.22066 - lgbm: 0.22314 - ens: 0.21557\n",
      "PET SUPPLIES               | lgbm: 0.45609 - lgbm: 0.46466 - lgbm: 0.45500 - lgbm: 0.45015 - ens: 0.45131\n",
      "PLAYERS AND ELECTRONICS    | lgbm: 0.44081 - lgbm: 0.44884 - lgbm: 0.44470 - lgbm: 0.44650 - ens: 0.43935\n",
      "POULTRY                    | lgbm: 0.19057 - lgbm: 0.20875 - lgbm: 0.18423 - lgbm: 0.19239 - ens: 0.18678\n",
      "PREPARED FOODS             | lgbm: 0.25958 - lgbm: 0.26013 - lgbm: 0.25977 - lgbm: 0.26131 - ens: 0.25421\n",
      "PRODUCE                    | lgbm: 0.12435 - lgbm: 0.13413 - lgbm: 0.12437 - lgbm: 0.13824 - ens: 0.12252\n",
      "SCHOOL AND OFFICE SUPPLIES | lgbm: 0.58223 - lgbm: 0.56863 - lgbm: 0.57520 - lgbm: 0.57250 - ens: 0.56625\n",
      "SEAFOOD                    | lgbm: 0.45119 - lgbm: 0.45522 - lgbm: 0.46157 - lgbm: 0.46779 - ens: 0.45082\n",
      "============================================================================================\n",
      "Average RMSLE | lgbm: 0.33467 - lgbm: 0.34526 - lgbm: 0.33465 - lgbm: 0.34124 - ens: 0.33246\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# # generate forecasts for model trained on the entire data\n",
    "# predictions1 = trainer.validate(\n",
    "#     model_names=ENS_MODELS, \n",
    "#     model_configs=ENS_CONFIGS,\n",
    "# )\n",
    "\n",
    "# generate forecasts for model trained on a subset of the data\n",
    "predictions2 = trainer.validate(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    "    drop_before=\"2015-01-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fe1742f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003988504409790039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting covariates",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a375a734da438ca7bf92aa00d68836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting covariates:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015956640243530273,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Setting up",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b1f7db770f40e386521c412c1d53e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting up:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01695394515991211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55eb6f39cdc5464eb9919298a33b9f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00498652458190918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0b2b3e100e42d8849de5a2b0c20fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# future covariates\n",
    "future_cols = [\n",
    "    \"oil\", \"onpromotion\",\n",
    "    \"day\", \"month\", \"year\", \"day_of_week\", \"day_of_year\", \"week_of_year\", \"date_index\",\n",
    "    \"work_day\", *selected_holidays,\n",
    "]\n",
    "\n",
    "holidays_to_add = ['N Batalla de Pichincha', 'N Carnaval', 'N Cyber Monday', 'N Independencia de Cuenca', 'N Independencia de Guayaquil', 'N Viernes Santo']\n",
    "\n",
    "# for new_holiday in holidays_to_add:\n",
    "#     future_cols.append(new_holiday)\n",
    "\n",
    "time_based_to_add = ['day_of_month', 'is_wknd', \n",
    "       'is_year_end', 'wageday', 'day_to_nearest_holiday', 'day_from_nearest_holiday', 'is_quarter_start', 'week_of_month',\n",
    "       'is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_start', 'is_month_end']\n",
    "\n",
    "izbaceni = ['is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_start', 'is_month_end']\n",
    "\n",
    "for time_based in time_based_to_add:\n",
    "    future_cols.append(time_based)\n",
    "\n",
    "# additional past and future covariates from computing the moving averages\n",
    "past_ma_cols = None\n",
    "future_ma_cols = [\"oil\", \"onpromotion\"]\n",
    "\n",
    "past_dict, future_dict = get_covariates(past_cols, future_cols, past_ma_cols, future_ma_cols)\n",
    "\n",
    "TRAINER_CONFIG = {\n",
    "    # the time series data previously extracted\n",
    "    \"target_dict\": target_dict,\n",
    "    \"pipe_dict\": pipe_dict,\n",
    "    \"id_dict\": id_dict,\n",
    "    \"past_dict\": past_dict,\n",
    "    \"future_dict\": future_dict,\n",
    "    \n",
    "    # time series cross-validation using a rolling forecasting origin\n",
    "    \"forecast_horizon\": 16, # the length of the validation set\n",
    "    \"folds\": 1, # the number of training sets (setting to 1 means the standard train-validation split)\n",
    "    \n",
    "    # the number of previous days to check for zero sales; if all are zero, generate zero forecasts\n",
    "    \"zero_fc_window\": 21,\n",
    "    \n",
    "    # specify the covariates in a list to include in the model\n",
    "    # set to None to not use any, and set to 'keep_all' to include everything\n",
    "    \"static_covs\": \"keep_all\", # specify from ['city', 'state', 'cluster', 'type', 'store_nbr'], will extract all one-hot encoded columns\n",
    "    \"past_covs\": \"keep_all\",\n",
    "    \"future_covs\": \"keep_all\",\n",
    "}\n",
    "\n",
    "# initialize model trainer\n",
    "trainer = Trainer(**TRAINER_CONFIG)\n",
    "\n",
    "GBDT_CONFIG1 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 120,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 300, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "GBDT_CONFIG2 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 14,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 150, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG3 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 365,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 200, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG4 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 730,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 100, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "# 'lgbm' for LightGBM, 'xgb' for XGBoost, 'cat' for CatBoost\n",
    "ENS_MODELS = [\"lgbm\", \"lgbm\", \"lgbm\", \"lgbm\"]\n",
    "ENS_CONFIGS = [GBDT_CONFIG1, GBDT_CONFIG2, GBDT_CONFIG3, GBDT_CONFIG4]\n",
    "\n",
    "# generate forecasts for model trained on the entire data\n",
    "predictions1 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    ")\n",
    "\n",
    "# generate forecasts for model trained on a subset of the data\n",
    "predictions2 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    "    drop_before=\"2015-01-01\",\n",
    ")\n",
    "\n",
    "# compute the average of the ensemble models\n",
    "final_predictions = predictions1.merge(\n",
    "    predictions2, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    ")\n",
    "final_predictions[\"sales\"] = final_predictions[[\"sales_x\", \"sales_y\"]].mean(axis=1)\n",
    "final_predictions = final_predictions.drop(columns=[\"sales_x\", \"sales_y\"])\n",
    "test = pd.read_csv('originalni_datasetovi/test.csv', parse_dates=['date'])\n",
    "\n",
    "def prepare_submission(predictions):\n",
    "    predictions = predictions.copy()\n",
    "    A\n",
    "    # process column values for merging\n",
    "    predictions.store_nbr = predictions.store_nbr.replace(\n",
    "        \"store_nbr_\", \"\", regex=True,\n",
    "    ).astype(int)\n",
    "     \n",
    "    # match with corresponding 'id'\n",
    "    submission = test.merge(\n",
    "        predictions, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    "    )[[\"id\", \"sales\"]]\n",
    "    \n",
    "    return submission\n",
    "\n",
    "submission = prepare_submission(final_predictions)\n",
    "submission.to_csv(\"submission_bez_praznika.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6951e4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013962984085083008,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting covariates",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb6165c136445ba9fb674457a66ba16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting covariates:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011967897415161133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Setting up",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e8592bd248409d82e231b5e25f6a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting up:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014960050582885742,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cc72a5ea72432dad0a19fc13d69b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.414135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 61803\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.463530\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34773\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.457790\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.812314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 124248\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.479173\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.743009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 217265\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.502870\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101768 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35943\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.027618\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27887\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.025993\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.134505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 53560\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.032732\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.130475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 73133\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.042897\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61703\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.359648\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34779\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.354674\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.964934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 123986\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.375021\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.746351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 216893\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.403510\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.592523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68583\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.559568\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41553\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.544152\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.358502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131028\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.601171\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.457904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224053\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.644399\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36468\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 856\n",
      "[LightGBM] [Info] Start training from score 0.015404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.101501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27670\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 750\n",
      "[LightGBM] [Info] Start training from score 0.014498\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.135666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50873\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1043\n",
      "[LightGBM] [Info] Start training from score 0.018256\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50823\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1028\n",
      "[LightGBM] [Info] Start training from score 0.025212\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.400181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68553\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.549480\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41523\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.541319\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.413483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130998\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.570471\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.454388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224023\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.602663\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 64413\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.327098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37383\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.307857\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.578365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126858\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.387672\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.626337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 219879\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.433466\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.535588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68583\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.515250\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.084449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41553\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.508706\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.359313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131028\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.532112\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.724309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224053\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.558908\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.424664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68583\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.612877\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41553\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.595554\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.406270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131028\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.655062\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.490838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224053\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.685413\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.415899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68568\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.579338\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41538\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.570052\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.352214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131013\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.601227\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.490167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224038\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.635215\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.435049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 67443\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.546731\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40413\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.539300\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.355399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129888\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.563799\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.878511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 222906\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.581334\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.400881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 67666\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.406865\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.064762 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40636\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.398453\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.358159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130111\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.419060\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.463004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223147\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.440170\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.792547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68583\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.507830\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41553\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.499144\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.362151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131028\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.524943\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.435686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224053\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.557558\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59973\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.441970\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32943\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.439145\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.540804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122418\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.446240\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.474565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 215443\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.461725\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.362445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 49199\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.216095\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063528 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29851\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.213560\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.798696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 91604\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.224566\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.692680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 147835\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.230147\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.379290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 67638\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.383049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40608\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.360517\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.716965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130083\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.453984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.903766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223108\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.524208\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.099070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 65434\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.384619\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 38404\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.361995\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.505673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127879\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.455845\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.649796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 220910\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.540615\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35214\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.128939\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27803\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.128064\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.174250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 51723\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.124686\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.438949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 73338\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.121902\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.406543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68062\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.524448\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41032\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.493598\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.030756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130507\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.621568\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.639024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223577\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.696137\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.147802 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 62682\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.266092\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35652\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.250440\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.496227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 125127\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.315369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.554081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 217990\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.346086\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.091295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60055\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.221300\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 33025\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.215980\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.553668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122500\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.236388\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.802508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 215513\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.254987\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.094769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 60610\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.397950\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.062170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 33580\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.399584\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.529849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 123055\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.394256\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.704611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 216080\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.388180\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.405597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 66033\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.499627\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 39003\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.494919\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.567823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128478\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.511345\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.721598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221503\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.536460\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075518 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58023\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.238303\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 31099\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.224285\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.472635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 120223\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.282433\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.527173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 213090\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.357888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.356402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68045\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.582542\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.323692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 41015\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.577721\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.347927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130490\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.591586\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.518749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223494\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.612725\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.565562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68460\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.526439\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41430\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.518714\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.359083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130905\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.547557\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.677697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223944\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.577477\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59613\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.278316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100912 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32689\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.261944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.725465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122019\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.329855\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.459903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 214967\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.380089\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061862 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61539\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.329231\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051510 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34509\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.309864\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.731923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 123984\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.390199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.496889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 216985\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.440802\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.357021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68293\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.618315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032792 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41263\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.606366\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.237588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130738\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.644109\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.548319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 223745\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.659563\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.451090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 64893\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.604929\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37863\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.599044\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.295363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127338\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.620984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.628656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 220350\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.648287\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.518130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68583\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.581192\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41553\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.549467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.108184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 131028\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.671285\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 2.053568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 224053\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.739710\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.191330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 64023\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.091394\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37099\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.086018\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.803353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126427\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.108319\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.264014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 219377\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.127983\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.298450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 61839\n",
      "[LightGBM] [Info] Number of data points in the train set: 84672, number of used features: 901\n",
      "[LightGBM] [Info] Start training from score 0.465791\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34809\n",
      "[LightGBM] [Info] Number of data points in the train set: 89964, number of used features: 795\n",
      "[LightGBM] [Info] Start training from score 0.465974\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.550711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 124284\n",
      "[LightGBM] [Info] Number of data points in the train set: 71442, number of used features: 1146\n",
      "[LightGBM] [Info] Start training from score 0.482369\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.418083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 217305\n",
      "[LightGBM] [Info] Number of data points in the train set: 51732, number of used features: 1496\n",
      "[LightGBM] [Info] Start training from score 0.506146\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011967658996582031,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060666e0aca5422cae969e76e6cd7918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 61683\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.511778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34672\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.503837\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.330276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 124254\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.520781\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.278558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 214152\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.539441\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.063989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35418\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.049035\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27786\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.043529\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 51426\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.061589\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 60456\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1386\n",
      "[LightGBM] [Info] Start training from score 0.058912\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.114013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61615\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.419682\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34734\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.404711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.215383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 123753\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.439480\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212994\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.464719\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.187632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68538\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.677964\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41508\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.647376\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.228382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130944\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.691979\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221184\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.721554\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36423\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 841\n",
      "[LightGBM] [Info] Start training from score 0.028822\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27625\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 735\n",
      "[LightGBM] [Info] Start training from score 0.025586\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 50789\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1028\n",
      "[LightGBM] [Info] Start training from score 0.040730\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 46576\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 933\n",
      "[LightGBM] [Info] Start training from score 0.045777\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 68508\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.609231\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038970 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41478\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.603155\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130914\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.617348\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221154\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.636103\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 64353\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.495117\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37323\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.439522\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.284438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126755\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.510961\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.125687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212930\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.517207\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.203984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68538\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.564638\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41508\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.558976\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130944\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.571384\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.140923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221169\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.595910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 68538\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.697932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41508\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.686541\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.209373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130944\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.716036\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094098 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221184\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.740332\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.252359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68523\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.639796\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41493\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.635499\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130929\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.641847\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221184\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.666470\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.170442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 67398\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.583599\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.111747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 40352\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.581243\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.219158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130339\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.589928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 219746\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.609769\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.318615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 67657\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.447549\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40614\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.440576\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.235439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130035\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.448058\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 220277\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.448403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.409652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68538\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.569778\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41508\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.558696\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.258604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130944\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.582818\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.110027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221184\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.604190\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.134799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59928\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.465160\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32898\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.461838\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.254883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122274\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.464234\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212157\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.502135\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46564\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.237620\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048433 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 29530\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.231908\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.400247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 81903\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.242119\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.169623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 113511\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1394\n",
      "[LightGBM] [Info] Start training from score 0.258953\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.319180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 67578\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.533454\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40549\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.524610\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.276566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 129977\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.541346\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 220066\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.566999\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.186647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65403\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.552425\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 38367\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.542091\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.476022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127827\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.559008\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 217992\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.589367\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 33503\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.112978\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.522059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27567\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.121017\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 46420\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.118694\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58020\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.162629\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.277127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68063\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.795049\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.111713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41033\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.705774\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.531292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130498\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.805569\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 220656\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.819389\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 62193\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.395301\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 35269\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.350913\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.243736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 124368\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.409605\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212169\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.423126\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 59875\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.262214\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32916\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.255964\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.274326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122266\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.284146\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212315\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.371052\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 60535\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.391148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033129 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 33520\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.388570\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.252111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122935\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.379000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212101\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.419069\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 65988\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.545989\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 38958\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.537503\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.327023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 128372\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.563311\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.133525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 218208\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.580973\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 57978\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.403679\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 31054\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.363095\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.264414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 120139\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.455371\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163680 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 209352\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1386\n",
      "[LightGBM] [Info] Start training from score 0.467066\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.287028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 67910\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.620294\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.329481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 40906\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.613535\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130285\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.625783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.156652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 220651\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.644180\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.290267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68425\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.584271\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41395\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.577630\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.351958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130803\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.592718\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.143260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 220914\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.607625\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.349777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 59568\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.434157\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 32644\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.385407\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.393244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121877\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.478852\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.256374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 211339\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.549409\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 61470\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.503419\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046976 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34440\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.446891\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.297230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 123876\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.531448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.176435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 212722\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.562175\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.232927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68180\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.665206\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41174\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.659957\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.296605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130518\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.667786\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.160889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 219997\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.678963\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.252475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 64788\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.657807\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37761\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.649266\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.341403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 127179\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.660824\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 216935\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.655901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.332414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 68538\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.831481\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.106309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 41508\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.748549\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.290251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 130944\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.865828\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.158593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 221184\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.881881\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.507633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 63984\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.146260\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 37054\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.129837\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.285153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 126353\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.163372\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 215618\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.182609\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 61668\n",
      "[LightGBM] [Info] Number of data points in the train set: 45252, number of used features: 886\n",
      "[LightGBM] [Info] Start training from score 0.509569\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34656\n",
      "[LightGBM] [Info] Number of data points in the train set: 50976, number of used features: 780\n",
      "[LightGBM] [Info] Start training from score 0.506553\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.205130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 124063\n",
      "[LightGBM] [Info] Number of data points in the train set: 32022, number of used features: 1131\n",
      "[LightGBM] [Info] Start training from score 0.516655\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.181266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 213416\n",
      "[LightGBM] [Info] Number of data points in the train set: 12312, number of used features: 1401\n",
      "[LightGBM] [Info] Start training from score 0.519759\n"
     ]
    }
   ],
   "source": [
    "# future covariates\n",
    "selected_holidays = [\n",
    "    \"nat_terremoto\", \"nat_navidad\", \"nat_dia la madre\", \"nat_dia trabajo\",\n",
    "    \"nat_primer dia ano\", \"nat_futbol\", \"nat_dia difuntos\", \"nat_batalla_de_pichincha\",\n",
    "    \"nat_carnaval\", 'nat_cyber_monday', 'nat_independencia_de_cuenca',\n",
    "    'nat_independencia_de_guayaquil', 'n_viernes_santo']\n",
    "\n",
    "future_cols = [\n",
    "    \"oil\", \"onpromotion\",\n",
    "    \"day\", \"month\", \"year\", \"day_of_week\", \"day_of_year\", \"week_of_year\", \"date_index\",\n",
    "    \"work_day\", *selected_holidays,\n",
    "]\n",
    "\n",
    "\n",
    "time_based_to_add = ['day_of_month', 'is_wknd', \n",
    "       'is_year_end', 'wageday', 'day_to_nearest_holiday', 'day_from_nearest_holiday', 'is_quarter_start', 'week_of_month',\n",
    "       'is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_start', 'is_month_end']\n",
    "\n",
    "izbaceni = ['is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_start', 'is_month_end']\n",
    "\n",
    "for time_based in time_based_to_add:\n",
    "    future_cols.append(time_based)\n",
    "\n",
    "# additional past and future covariates from computing the moving averages\n",
    "past_ma_cols = None\n",
    "future_ma_cols = [\"oil\", \"onpromotion\"]\n",
    "\n",
    "past_dict, future_dict = get_covariates(past_cols, future_cols, past_ma_cols, future_ma_cols)\n",
    "\n",
    "TRAINER_CONFIG = {\n",
    "    # the time series data previously extracted\n",
    "    \"target_dict\": target_dict,\n",
    "    \"pipe_dict\": pipe_dict,\n",
    "    \"id_dict\": id_dict,\n",
    "    \"past_dict\": past_dict,\n",
    "    \"future_dict\": future_dict,\n",
    "    \n",
    "    # time series cross-validation using a rolling forecasting origin\n",
    "    \"forecast_horizon\": 16, # the length of the validation set\n",
    "    \"folds\": 1, # the number of training sets (setting to 1 means the standard train-validation split)\n",
    "    \n",
    "    # the number of previous days to check for zero sales; if all are zero, generate zero forecasts\n",
    "    \"zero_fc_window\": 21,\n",
    "    \n",
    "    # specify the covariates in a list to include in the model\n",
    "    # set to None to not use any, and set to 'keep_all' to include everything\n",
    "    \"static_covs\": \"keep_all\", # specify from ['city', 'state', 'cluster', 'type', 'store_nbr'], will extract all one-hot encoded columns\n",
    "    \"past_covs\": \"keep_all\",\n",
    "    \"future_covs\": \"keep_all\",\n",
    "}\n",
    "\n",
    "# initialize model trainer\n",
    "trainer = Trainer(**TRAINER_CONFIG)\n",
    "\n",
    "GBDT_CONFIG1 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 120,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "}\n",
    "\n",
    "GBDT_CONFIG2 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 14,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG3 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 365,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG4 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 730,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \"output_chunk_length\": 1,\n",
    "    \n",
    "}\n",
    "\n",
    "# 'lgbm' for LightGBM, 'xgb' for XGBoost, 'cat' for CatBoost\n",
    "ENS_MODELS = [\"lgbm\", \"lgbm\", \"lgbm\", \"lgbm\"]\n",
    "ENS_CONFIGS = [GBDT_CONFIG1, GBDT_CONFIG2, GBDT_CONFIG3, GBDT_CONFIG4]\n",
    "\n",
    "# generate forecasts for model trained on the entire data\n",
    "predictions1 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    ")\n",
    "\n",
    "# generate forecasts for model trained on a subset of the data\n",
    "predictions2 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    "    drop_before=\"2015-01-01\",\n",
    ")\n",
    "\n",
    "# compute the average of the ensemble models\n",
    "final_predictions = predictions1.merge(\n",
    "    predictions2, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    ")\n",
    "final_predictions[\"sales\"] = final_predictions[[\"sales_x\", \"sales_y\"]].mean(axis=1)\n",
    "final_predictions = final_predictions.drop(columns=[\"sales_x\", \"sales_y\"])\n",
    "test = pd.read_csv('originalni_datasetovi/test.csv', parse_dates=['date'])\n",
    "\n",
    "def prepare_submission(predictions):\n",
    "    predictions = predictions.copy()\n",
    "    \n",
    "    # process column values for merging\n",
    "    predictions.store_nbr = predictions.store_nbr.replace(\n",
    "        \"store_nbr_\", \"\", regex=True,\n",
    "    ).astype(int)\n",
    "     \n",
    "    # match with corresponding 'id'\n",
    "    submission = test.merge(\n",
    "        predictions, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    "    )[[\"id\", \"sales\"]]\n",
    "    \n",
    "    return submission\n",
    "\n",
    "submission = prepare_submission(final_predictions)\n",
    "submission.to_csv(\"submission_def_lgbm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eae16eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005985260009765625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting covariates",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294ad607a2974615ac84bdc6e2946ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting covariates:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Setting up",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e04dab7cf04e01af701d2fe918e2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting up:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01920914649963379,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaba1bde5fd34c86a715a9c0109ecee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003991127014160156,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fe5c05ac6c4bd1bc060bedf8fda66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# future covariates\n",
    "selected_holidays = [\n",
    "    \"nat_terremoto\", \"nat_navidad\", \"nat_dia la madre\", \"nat_dia trabajo\",\n",
    "    \"nat_primer dia ano\", \"nat_futbol\", \"nat_dia difuntos\", \"nat_batalla_de_pichincha\",\n",
    "    \"nat_carnaval\", 'nat_cyber_monday', 'nat_independencia_de_cuenca',\n",
    "    'nat_independencia_de_guayaquil', 'n_viernes_santo']\n",
    "future_cols = [\n",
    "    \"oil\", \"onpromotion\",\n",
    "    \"day\", \"month\", \"year\", \"day_of_week\", \"day_of_year\", \"week_of_year\", \"date_index\",\n",
    "    \"work_day\", *selected_holidays,\n",
    "]\n",
    "\n",
    "\n",
    "time_based_to_add = ['day_of_month', 'is_wknd', 'wageday', 'day_to_nearest_holiday','is_month_start', 'day_from_nearest_holiday', 'is_quarter_start', 'week_of_month']\n",
    "\n",
    "izbaceni = ['is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_end', 'is_year_end']\n",
    "\n",
    "for time_based in time_based_to_add:\n",
    "    future_cols.append(time_based)\n",
    "\n",
    "# additional past and future covariates from computing the moving averages\n",
    "past_ma_cols = None\n",
    "future_ma_cols = [\"oil\", \"onpromotion\"]\n",
    "\n",
    "past_dict, future_dict = get_covariates(past_cols, future_cols, past_ma_cols, future_ma_cols)\n",
    "\n",
    "TRAINER_CONFIG = {\n",
    "    # the time series data previously extracted\n",
    "    \"target_dict\": target_dict,\n",
    "    \"pipe_dict\": pipe_dict,\n",
    "    \"id_dict\": id_dict,\n",
    "    \"past_dict\": past_dict,\n",
    "    \"future_dict\": future_dict,\n",
    "    \n",
    "    # time series cross-validation using a rolling forecasting origin\n",
    "    \"forecast_horizon\": 16, # the length of the validation set\n",
    "    \"folds\": 1, # the number of training sets (setting to 1 means the standard train-validation split)\n",
    "    \n",
    "    # the number of previous days to check for zero sales; if all are zero, generate zero forecasts\n",
    "    \"zero_fc_window\": 21,\n",
    "    \n",
    "    # specify the covariates in a list to include in the model\n",
    "    # set to None to not use any, and set to 'keep_all' to include everything\n",
    "    \"static_covs\": \"keep_all\", # specify from ['city', 'state', 'cluster', 'type', 'store_nbr'], will extract all one-hot encoded columns\n",
    "    \"past_covs\": \"keep_all\",\n",
    "    \"future_covs\": \"keep_all\",\n",
    "}\n",
    "\n",
    "# initialize model trainer\n",
    "trainer = Trainer(**TRAINER_CONFIG)\n",
    "\n",
    "GBDT_CONFIG1 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 120,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 300, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "GBDT_CONFIG2 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 14,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 150, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG3 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 365,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 200, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG4 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 730,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 100, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "# 'lgbm' for LightGBM, 'xgb' for XGBoost, 'cat' for CatBoost\n",
    "ENS_MODELS = [\"lgbm\", \"lgbm\", \"lgbm\", \"lgbm\"]\n",
    "ENS_CONFIGS = [GBDT_CONFIG1, GBDT_CONFIG2, GBDT_CONFIG3, GBDT_CONFIG4]\n",
    "\n",
    "# generate forecasts for model trained on the entire data\n",
    "predictions1 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    ")\n",
    "\n",
    "# generate forecasts for model trained on a subset of the data\n",
    "predictions2 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    "    drop_before=\"2015-01-01\",\n",
    ")\n",
    "\n",
    "# compute the average of the ensemble models\n",
    "final_predictions = predictions1.merge(\n",
    "    predictions2, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    ")\n",
    "final_predictions[\"sales\"] = final_predictions[[\"sales_x\", \"sales_y\"]].mean(axis=1)\n",
    "final_predictions = final_predictions.drop(columns=[\"sales_x\", \"sales_y\"])\n",
    "test = pd.read_csv('originalni_datasetovi/test.csv', parse_dates=['date'])\n",
    "\n",
    "def prepare_submission(predictions):\n",
    "    predictions = predictions.copy()\n",
    "    \n",
    "    # process column values for merging\n",
    "    predictions.store_nbr = predictions.store_nbr.replace(\n",
    "        \"store_nbr_\", \"\", regex=True,\n",
    "    ).astype(int)\n",
    "     \n",
    "    # match with corresponding 'id'\n",
    "    submission = test.merge(\n",
    "        predictions, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    "    )[[\"id\", \"sales\"]]\n",
    "    \n",
    "    return submission\n",
    "\n",
    "submission = prepare_submission(final_predictions)\n",
    "submission.to_csv(\"submission_bez_time_neki.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2faf12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003989696502685547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting covariates",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de91603de70846fc8ff63f89751d6f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting covariates:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011968612670898438,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Setting up",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00145b29f14147718c9fc8aca165b5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Setting up:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017952919006347656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7dc89cde6a4728974862e319ebabc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003015279769897461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating forecasts",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a97f1e1bec7402c82cdca1c75c13686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# future covariates\n",
    "selected_holidays = [\n",
    "    \"nat_terremoto\", \"nat_navidad\", \"nat_dia la madre\", \"nat_dia trabajo\",\n",
    "    \"nat_primer dia ano\", \"nat_futbol\", \"nat_dia difuntos\", \"nat_batalla_de_pichincha\",\n",
    "    \"nat_carnaval\", 'nat_cyber_monday', 'nat_independencia_de_cuenca',\n",
    "    'nat_independencia_de_guayaquil', 'n_viernes_santo']\n",
    "\n",
    "\n",
    "future_cols = [\n",
    "    \"oil\", \"onpromotion\",\n",
    "    \"day\", \"month\", \"year\", \"day_of_week\", \"day_of_year\", \"week_of_year\", \"date_index\",\n",
    "    \"work_day\", *selected_holidays,\n",
    "]\n",
    "\n",
    "\n",
    "# time_based_to_add = ['day_of_month', 'is_wknd', 'wageday', 'day_to_nearest_holiday','is_month_start', 'day_from_nearest_holiday', 'is_quarter_start', 'week_of_month']\n",
    "\n",
    "# izbaceni = ['is_year_start', 'is_quarter_end', 'quarter', 'season', 'is_quarter_end', 'is_month_end', 'is_year_end']\n",
    "\n",
    "# for time_based in time_based_to_add:\n",
    "#     future_cols.append(time_based)\n",
    "\n",
    "# additional past and future covariates from computing the moving averages\n",
    "past_ma_cols = None\n",
    "future_ma_cols = [\"oil\", \"onpromotion\"]\n",
    "\n",
    "past_dict, future_dict = get_covariates(past_cols, future_cols, past_ma_cols, future_ma_cols)\n",
    "\n",
    "TRAINER_CONFIG = {\n",
    "    # the time series data previously extracted\n",
    "    \"target_dict\": target_dict,\n",
    "    \"pipe_dict\": pipe_dict,\n",
    "    \"id_dict\": id_dict,\n",
    "    \"past_dict\": past_dict,\n",
    "    \"future_dict\": future_dict,\n",
    "    \n",
    "    # time series cross-validation using a rolling forecasting origin\n",
    "    \"forecast_horizon\": 16, # the length of the validation set\n",
    "    \"folds\": 1, # the number of training sets (setting to 1 means the standard train-validation split)\n",
    "    \n",
    "    # the number of previous days to check for zero sales; if all are zero, generate zero forecasts\n",
    "    \"zero_fc_window\": 21,\n",
    "    \n",
    "    # specify the covariates in a list to include in the model\n",
    "    # set to None to not use any, and set to 'keep_all' to include everything\n",
    "    \"static_covs\": \"keep_all\", # specify from ['city', 'state', 'cluster', 'type', 'store_nbr'], will extract all one-hot encoded columns\n",
    "    \"past_covs\": \"keep_all\",\n",
    "    \"future_covs\": \"keep_all\",\n",
    "}\n",
    "\n",
    "# initialize model trainer\n",
    "trainer = Trainer(**TRAINER_CONFIG)\n",
    "\n",
    "GBDT_CONFIG1 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 120,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 300, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "}\n",
    "\n",
    "GBDT_CONFIG2 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 14,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 150, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG3 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 365,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 200, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "GBDT_CONFIG4 = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 730,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)) if TRAINER_CONFIG[\"past_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1) if TRAINER_CONFIG[\"future_covs\"] is not None else None,\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "    \"n_estimators\": 100, # num_iterations 100\n",
    "    \"learning_rate\": 0.05, # 0.1\n",
    "    #\"max_depth\": -1, # -1 useful when data is small\n",
    "    \"subsample\": 1, # 1\n",
    "    \"lambda_l1\": 0, # l1 0\n",
    "    \"lambda_l2\": 0, # l2  0\n",
    "    \"verbose\":-1\n",
    "    \n",
    "}\n",
    "\n",
    "# 'lgbm' for LightGBM, 'xgb' for XGBoost, 'cat' for CatBoost\n",
    "ENS_MODELS = [\"lgbm\", \"lgbm\", \"lgbm\", \"lgbm\"]\n",
    "ENS_CONFIGS = [GBDT_CONFIG1, GBDT_CONFIG2, GBDT_CONFIG3, GBDT_CONFIG4]\n",
    "\n",
    "# generate forecasts for model trained on the entire data\n",
    "predictions1 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    ")\n",
    "\n",
    "# generate forecasts for model trained on a subset of the data\n",
    "predictions2 = trainer.ensemble_predict(\n",
    "    model_names=ENS_MODELS, \n",
    "    model_configs=ENS_CONFIGS,\n",
    "    drop_before=\"2015-01-01\",\n",
    ")\n",
    "\n",
    "# compute the average of the ensemble models\n",
    "final_predictions = predictions1.merge(\n",
    "    predictions2, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    ")\n",
    "final_predictions[\"sales\"] = final_predictions[[\"sales_x\", \"sales_y\"]].mean(axis=1)\n",
    "final_predictions = final_predictions.drop(columns=[\"sales_x\", \"sales_y\"])\n",
    "test = pd.read_csv('originalni_datasetovi/test.csv', parse_dates=['date'])\n",
    "\n",
    "def prepare_submission(predictions):\n",
    "    predictions = predictions.copy()\n",
    "    \n",
    "    # process column values for merging\n",
    "    predictions.store_nbr = predictions.store_nbr.replace(\n",
    "        \"store_nbr_\", \"\", regex=True,\n",
    "    ).astype(int)\n",
    "     \n",
    "    # match with corresponding 'id'\n",
    "    submission = test.merge(\n",
    "        predictions, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    "    )[[\"id\", \"sales\"]]\n",
    "    \n",
    "    return submission\n",
    "\n",
    "submission = prepare_submission(final_predictions)\n",
    "submission.to_csv(\"submission_bez_nasih.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d7e9e5ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T11:26:45.020625Z",
     "iopub.status.busy": "2023-07-14T11:26:45.020152Z",
     "iopub.status.idle": "2023-07-14T11:26:45.054353Z",
     "shell.execute_reply": "2023-07-14T11:26:45.052899Z"
    },
    "papermill": {
     "duration": 0.099044,
     "end_time": "2023-07-14T11:26:45.056844",
     "exception": false,
     "start_time": "2023-07-14T11:26:44.957800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.440428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.352807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>3.785472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>4.443590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>store_nbr_1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>2.313947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    store_nbr      family     sales\n",
       "0 2017-08-16  store_nbr_1  AUTOMOTIVE  3.440428\n",
       "1 2017-08-17  store_nbr_1  AUTOMOTIVE  3.352807\n",
       "2 2017-08-18  store_nbr_1  AUTOMOTIVE  3.785472\n",
       "3 2017-08-19  store_nbr_1  AUTOMOTIVE  4.443590\n",
       "4 2017-08-20  store_nbr_1  AUTOMOTIVE  2.313947"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the average of the ensemble models\n",
    "final_predictions = predictions1.merge(\n",
    "    predictions2, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    ")\n",
    "final_predictions[\"sales\"] = final_predictions[[\"sales_x\", \"sales_y\"]].mean(axis=1)\n",
    "final_predictions = final_predictions.drop(columns=[\"sales_x\", \"sales_y\"])\n",
    "\n",
    "final_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e55a6ce",
   "metadata": {
    "papermill": {
     "duration": 0.057674,
     "end_time": "2023-07-14T11:26:45.171371",
     "exception": false,
     "start_time": "2023-07-14T11:26:45.113697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preparing for the submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a8672d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T11:26:45.287882Z",
     "iopub.status.busy": "2023-07-14T11:26:45.287186Z",
     "iopub.status.idle": "2023-07-14T11:26:45.293284Z",
     "shell.execute_reply": "2023-07-14T11:26:45.291892Z"
    },
    "papermill": {
     "duration": 0.067498,
     "end_time": "2023-07-14T11:26:45.295770",
     "exception": false,
     "start_time": "2023-07-14T11:26:45.228272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('originalni_datasetovi/test.csv', parse_dates=['date'])\n",
    "\n",
    "def prepare_submission(predictions):\n",
    "    predictions = predictions.copy()\n",
    "    \n",
    "    # process column values for merging\n",
    "    predictions.store_nbr = predictions.store_nbr.replace(\n",
    "        \"store_nbr_\", \"\", regex=True,\n",
    "    ).astype(int)\n",
    "     \n",
    "    # match with corresponding 'id'\n",
    "    submission = test.merge(\n",
    "        predictions, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    "    )[[\"id\", \"sales\"]]\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e75e6e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T11:26:45.411296Z",
     "iopub.status.busy": "2023-07-14T11:26:45.410883Z",
     "iopub.status.idle": "2023-07-14T11:26:45.476714Z",
     "shell.execute_reply": "2023-07-14T11:26:45.475323Z"
    },
    "papermill": {
     "duration": 0.126571,
     "end_time": "2023-07-14T11:26:45.479563",
     "exception": false,
     "start_time": "2023-07-14T11:26:45.352992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>3.440428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>4.219843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2409.537119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>0.041166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        sales\n",
       "0  3000888     3.440428\n",
       "1  3000889     0.000000\n",
       "2  3000890     4.219843\n",
       "3  3000891  2409.537119\n",
       "4  3000892     0.041166"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submission = prepare_submission(final_predictions)\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4fabcb61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T11:26:45.595571Z",
     "iopub.status.busy": "2023-07-14T11:26:45.595216Z",
     "iopub.status.idle": "2023-07-14T11:26:45.659066Z",
     "shell.execute_reply": "2023-07-14T11:26:45.657342Z"
    },
    "papermill": {
     "duration": 0.124447,
     "end_time": "2023-07-14T11:26:45.661655",
     "exception": false,
     "start_time": "2023-07-14T11:26:45.537208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4462f2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6234.634703,
   "end_time": "2023-07-14T11:26:48.771821",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-14T09:42:54.137118",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "037cd923dede43eba7339c9d34267ac9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b57ddd51209d4315a493ab34629f2702",
        "IPY_MODEL_dc4e7ff07db3459f9ade1e64fedc6c32",
        "IPY_MODEL_bd05b1389e4d4525812dfece23d90b6f"
       ],
       "layout": "IPY_MODEL_29c06e03d0984e83a94a6d3506360552"
      }
     },
     "0463223cdb5d4199985f181eddac9810": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "09e7b01d52544c5fb2cbde2323b94d31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0ea63b0987ed4cab96a2fd30955cdfff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "104459c6b37f4ca3a5a324bb7288798f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "13357e0ca84a40e78d3b9b6ae219e93b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14dc5d9602514de2bac64fc762a926f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87b9faa475ba4cf5acfa49e912ef68d8",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6e7b9c275e5b49fd9186842f903e445f",
       "value": 33
      }
     },
     "1e45a7add1ad4937b4d4210468410ea7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1e92c490517f4ef290a9260f0c8c46ec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ebcba3fd6864677ac5849b87cbbeb37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a484c8a1b71a474c9920a00b5023e3aa",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_54c0968ce51f4cb8ad30982479e0473f",
       "value": "Extracting covariates: 100%"
      }
     },
     "23b62284eb734a9ba8e4bc9c9266695e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26c495562fbd4fe79d1e067e4334ea4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2926aa5902904d4f8fafcd22ee68e4f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_636513c9ae894e58ac106c2463e096d2",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_fd805015a10a491bbb768a78bc1a1546",
       "value": 33
      }
     },
     "29c06e03d0984e83a94a6d3506360552": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a2e856e2e10421f9cfe5560f6798b5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_728333fc706f4072823295aee2f0d215",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_76c73082a3394091b047411b28f6950e",
       "value": "Generating forecasts: 100%"
      }
     },
     "2dde9339ae6c492d8daac0ca9da4fdec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "489a3c89802b43c8b0e270513551d419": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d62b1e3b6e54c569f13ff01c4f74496": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c8eec52e87ce4f11b40b8a2fd410276e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_82f0e2491e494304977430fd5053cff3",
       "value": "Generating forecasts: 100%"
      }
     },
     "4d6ddc64da4947d68778e138b5c4db8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e6f8bb1024e40708413f85b13f1dcc0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ea739ebfa5a4af29469586044b77d0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5064eb3dbe7148edb19ca553ecdb4f22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7b749c8c2167474a962f0ab10ed6c74c",
        "IPY_MODEL_2926aa5902904d4f8fafcd22ee68e4f2",
        "IPY_MODEL_8429278751774faa83e7e67cd3695da5"
       ],
       "layout": "IPY_MODEL_13357e0ca84a40e78d3b9b6ae219e93b"
      }
     },
     "50df8e708eb2439e9db9bfeed584bd39": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_94f110343f0a43aa8fa1cddcf9db7798",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_104459c6b37f4ca3a5a324bb7288798f",
       "value": "Performing validation: 100%"
      }
     },
     "53ba658a141f4fa2a44d674e4b9505af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53ec3174c43945ec92df721445c506ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_837f2b8c16a04c959c84351dfb148f0c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0ea63b0987ed4cab96a2fd30955cdfff",
       "value": " 33/33 [00:00&lt;00:00, 3261.51it/s]"
      }
     },
     "54c0968ce51f4cb8ad30982479e0473f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5798f22e2a914b19b177bf0ffde487ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ebcba3fd6864677ac5849b87cbbeb37",
        "IPY_MODEL_ad455111575a4817a5095461256fd851",
        "IPY_MODEL_78b3ecf938ff4a809f20fc05f7f4600e"
       ],
       "layout": "IPY_MODEL_57c024fc08bb4abbbc0c091cd57c6009"
      }
     },
     "57c024fc08bb4abbbc0c091cd57c6009": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d33c3fbded24cafa26783cb7d5ec2ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1e45a7add1ad4937b4d4210468410ea7",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6432de5fc7cb48e285487097742ee461",
       "value": " 33/33 [24:47&lt;00:00, 45.35s/it]"
      }
     },
     "6279c2ca716f4c5f91c1d321d8432cde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4d62b1e3b6e54c569f13ff01c4f74496",
        "IPY_MODEL_9ae962307c664d699b0b38963a744ed0",
        "IPY_MODEL_90eee6c9ac784543b85118eedea26d6a"
       ],
       "layout": "IPY_MODEL_489a3c89802b43c8b0e270513551d419"
      }
     },
     "636513c9ae894e58ac106c2463e096d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6432de5fc7cb48e285487097742ee461": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "67967d7e1ab547a091713bd5106a9b0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6e7b9c275e5b49fd9186842f903e445f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7083e4d3011243c680bfe6d68a085f3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "72085e3b008e4f5db8d2aba7de561acd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f6a66b6eb3b640fca553b6f50a28c0e4",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_788d7a37e3914d34b8d2ed3758354b9d",
       "value": " 33/33 [01:47&lt;00:00,  3.22s/it]"
      }
     },
     "728333fc706f4072823295aee2f0d215": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76c73082a3394091b047411b28f6950e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "77f0514586764a5cb5320daeb2286ad3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "788d7a37e3914d34b8d2ed3758354b9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "78b3ecf938ff4a809f20fc05f7f4600e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4e6f8bb1024e40708413f85b13f1dcc0",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2dde9339ae6c492d8daac0ca9da4fdec",
       "value": " 33/33 [01:28&lt;00:00,  2.74s/it]"
      }
     },
     "7b749c8c2167474a962f0ab10ed6c74c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4ea739ebfa5a4af29469586044b77d0f",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f3b3ffc5c90e4b648632bd873ec34994",
       "value": "Extracting target series: 100%"
      }
     },
     "7b8adf91fd164927ac0624ffaec6bed9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f671142f99d74bc891d2bc4ab23d080a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_bbbe6f1a47614eafb1db93a8deffa1de",
       "value": "Setting up: 100%"
      }
     },
     "82f0e2491e494304977430fd5053cff3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "837f2b8c16a04c959c84351dfb148f0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8429278751774faa83e7e67cd3695da5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ee5c5159b3a14ca89f53e23e12529e26",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_ac33086bab37417eb53543965f954ec8",
       "value": " 33/33 [01:28&lt;00:00,  2.59s/it]"
      }
     },
     "87b9faa475ba4cf5acfa49e912ef68d8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8922c73505984bd28c5efcf5e8c09d59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e63ed642a0c40ce840c0169aab09ee4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "90234f5e3d8443fc981adcd66d4f1a14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "90eee6c9ac784543b85118eedea26d6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0463223cdb5d4199985f181eddac9810",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_09e7b01d52544c5fb2cbde2323b94d31",
       "value": " 33/33 [46:40&lt;00:00, 81.54s/it]"
      }
     },
     "94f110343f0a43aa8fa1cddcf9db7798": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ae962307c664d699b0b38963a744ed0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_23b62284eb734a9ba8e4bc9c9266695e",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_77f0514586764a5cb5320daeb2286ad3",
       "value": 33
      }
     },
     "a47ed44e9c974309ae3171426e7f722d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a484c8a1b71a474c9920a00b5023e3aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac33086bab37417eb53543965f954ec8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ad455111575a4817a5095461256fd851": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8922c73505984bd28c5efcf5e8c09d59",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_90234f5e3d8443fc981adcd66d4f1a14",
       "value": 33
      }
     },
     "ad93d37f603b4cd7a227c16926bcee5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b266608819a64f568c0be79c9e09d652": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b2cfe4661c56413dbf263f3a27628ec7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b57ddd51209d4315a493ab34629f2702": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1e92c490517f4ef290a9260f0c8c46ec",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_8e63ed642a0c40ce840c0169aab09ee4",
       "value": "Performing validation: 100%"
      }
     },
     "bbbe6f1a47614eafb1db93a8deffa1de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bd05b1389e4d4525812dfece23d90b6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cd3b790ef0324dbfa0d624d0c34e32fb",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a47ed44e9c974309ae3171426e7f722d",
       "value": " 33/33 [25:27&lt;00:00, 46.60s/it]"
      }
     },
     "c2742e849b6647a3b080d4c20a4fffa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2a2e856e2e10421f9cfe5560f6798b5d",
        "IPY_MODEL_14dc5d9602514de2bac64fc762a926f4",
        "IPY_MODEL_5d33c3fbded24cafa26783cb7d5ec2ea"
       ],
       "layout": "IPY_MODEL_4d6ddc64da4947d68778e138b5c4db8c"
      }
     },
     "c8eec52e87ce4f11b40b8a2fd410276e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc3d07f43793462eb46d571d68afd072": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e5993e5b7cf048e994ee1a065778d245",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_26c495562fbd4fe79d1e067e4334ea4a",
       "value": 33
      }
     },
     "cd3b790ef0324dbfa0d624d0c34e32fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc4e7ff07db3459f9ade1e64fedc6c32": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b2cfe4661c56413dbf263f3a27628ec7",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7083e4d3011243c680bfe6d68a085f3e",
       "value": 33
      }
     },
     "e01db192aadd4baf9340a61daf7390d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ad93d37f603b4cd7a227c16926bcee5c",
       "max": 33,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b266608819a64f568c0be79c9e09d652",
       "value": 33
      }
     },
     "e5993e5b7cf048e994ee1a065778d245": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee5c5159b3a14ca89f53e23e12529e26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f35acb15491a41eca64ab53562919624": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_50df8e708eb2439e9db9bfeed584bd39",
        "IPY_MODEL_cc3d07f43793462eb46d571d68afd072",
        "IPY_MODEL_72085e3b008e4f5db8d2aba7de561acd"
       ],
       "layout": "IPY_MODEL_53ba658a141f4fa2a44d674e4b9505af"
      }
     },
     "f3b3ffc5c90e4b648632bd873ec34994": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f671142f99d74bc891d2bc4ab23d080a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6a66b6eb3b640fca553b6f50a28c0e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb4165b06f274459b074490f9616c246": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7b8adf91fd164927ac0624ffaec6bed9",
        "IPY_MODEL_e01db192aadd4baf9340a61daf7390d4",
        "IPY_MODEL_53ec3174c43945ec92df721445c506ee"
       ],
       "layout": "IPY_MODEL_67967d7e1ab547a091713bd5106a9b0e"
      }
     },
     "fd805015a10a491bbb768a78bc1a1546": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
