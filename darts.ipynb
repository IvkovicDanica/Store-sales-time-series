{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216 from C header, got 232 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing import Pipeline\n",
    "from darts.dataprocessing.transformers import Scaler, InvertibleMapper, StaticCovariatesTransformer\n",
    "from darts.dataprocessing.transformers.missing_values_filler import MissingValuesFiller\n",
    "from darts.metrics import rmsle\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from darts.models import LinearRegressionModel, LightGBMModel, XGBModel, CatBoostModel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>work_day</th>\n",
       "      <th>N Batalla de Pichincha</th>\n",
       "      <th>N Carnaval</th>\n",
       "      <th>N Cyber Monday</th>\n",
       "      <th>N Dia de Difuntos</th>\n",
       "      <th>N Dia de la Madre</th>\n",
       "      <th>N Dia del Trabajo</th>\n",
       "      <th>N Futbol</th>\n",
       "      <th>N Independencia de Cuenca</th>\n",
       "      <th>N Independencia de Guayaquil</th>\n",
       "      <th>N Navidad</th>\n",
       "      <th>N Primer dia del ano</th>\n",
       "      <th>N Terremoto Manabi</th>\n",
       "      <th>N Viernes Santo</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>transactions</th>\n",
       "      <th>lag_16_sales</th>\n",
       "      <th>lag_17_sales</th>\n",
       "      <th>lag_18_sales</th>\n",
       "      <th>lag_19_sales</th>\n",
       "      <th>lag_20_sales</th>\n",
       "      <th>lag_30_sales</th>\n",
       "      <th>lag_365_sales</th>\n",
       "      <th>lag_730_sales</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>year</th>\n",
       "      <th>is_wknd</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>date_index</th>\n",
       "      <th>season</th>\n",
       "      <th>workday</th>\n",
       "      <th>wageday</th>\n",
       "      <th>day_to_nearest_holiday</th>\n",
       "      <th>day_from_nearest_holiday</th>\n",
       "      <th>lag_1_oil</th>\n",
       "      <th>lag_2_oil</th>\n",
       "      <th>lag_3_oil</th>\n",
       "      <th>lag_4_oil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr      family  sales  onpromotion   city      state  \\\n",
       "0 2013-01-01          1  AUTOMOTIVE    0.0          0.0  Quito  Pichincha   \n",
       "1 2013-01-01          1   BABY CARE    0.0          0.0  Quito  Pichincha   \n",
       "2 2013-01-01          1      BEAUTY    0.0          0.0  Quito  Pichincha   \n",
       "3 2013-01-01          1   BEVERAGES    0.0          0.0  Quito  Pichincha   \n",
       "4 2013-01-01          1       BOOKS    0.0          0.0  Quito  Pichincha   \n",
       "\n",
       "  type  cluster  work_day  N Batalla de Pichincha  N Carnaval  N Cyber Monday  \\\n",
       "0    D       13         0                       0           0               0   \n",
       "1    D       13         0                       0           0               0   \n",
       "2    D       13         0                       0           0               0   \n",
       "3    D       13         0                       0           0               0   \n",
       "4    D       13         0                       0           0               0   \n",
       "\n",
       "   N Dia de Difuntos  N Dia de la Madre  N Dia del Trabajo  N Futbol  \\\n",
       "0                  0                  0                  0         0   \n",
       "1                  0                  0                  0         0   \n",
       "2                  0                  0                  0         0   \n",
       "3                  0                  0                  0         0   \n",
       "4                  0                  0                  0         0   \n",
       "\n",
       "   N Independencia de Cuenca  N Independencia de Guayaquil  N Navidad  \\\n",
       "0                          0                             0          0   \n",
       "1                          0                             0          0   \n",
       "2                          0                             0          0   \n",
       "3                          0                             0          0   \n",
       "4                          0                             0          0   \n",
       "\n",
       "   N Primer dia del ano  N Terremoto Manabi  N Viernes Santo  oil_price  \\\n",
       "0                     1                   0                0      93.14   \n",
       "1                     1                   0                0      93.14   \n",
       "2                     1                   0                0      93.14   \n",
       "3                     1                   0                0      93.14   \n",
       "4                     1                   0                0      93.14   \n",
       "\n",
       "   transactions  lag_16_sales  lag_17_sales  lag_18_sales  lag_19_sales  \\\n",
       "0           0.0           NaN           NaN           NaN           NaN   \n",
       "1           0.0           NaN           NaN           NaN           NaN   \n",
       "2           0.0           NaN           NaN           NaN           NaN   \n",
       "3           0.0           NaN           NaN           NaN           NaN   \n",
       "4           0.0           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   lag_20_sales  lag_30_sales  lag_365_sales  lag_730_sales  month  \\\n",
       "0           NaN           NaN            NaN            NaN      1   \n",
       "1           NaN           NaN            NaN            NaN      1   \n",
       "2           NaN           NaN            NaN            NaN      1   \n",
       "3           NaN           NaN            NaN            NaN      1   \n",
       "4           NaN           NaN            NaN            NaN      1   \n",
       "\n",
       "   day_of_month  day_of_year  week_of_month  week_of_year  day_of_week  year  \\\n",
       "0             1            1              1             1            2  2013   \n",
       "1             1            1              1             1            2  2013   \n",
       "2             1            1              1             1            2  2013   \n",
       "3             1            1              1             1            2  2013   \n",
       "4             1            1              1             1            2  2013   \n",
       "\n",
       "   is_wknd  quarter  is_month_start  is_month_end  is_quarter_start  \\\n",
       "0        0        1               1             0                 1   \n",
       "1        0        1               1             0                 1   \n",
       "2        0        1               1             0                 1   \n",
       "3        0        1               1             0                 1   \n",
       "4        0        1               1             0                 1   \n",
       "\n",
       "   is_quarter_end  is_year_start  is_year_end  date_index  season  workday  \\\n",
       "0               0              1            0           0       0        0   \n",
       "1               0              1            0           0       0        0   \n",
       "2               0              1            0           0       0        0   \n",
       "3               0              1            0           0       0        0   \n",
       "4               0              1            0           0       0        0   \n",
       "\n",
       "   wageday  day_to_nearest_holiday  day_from_nearest_holiday  lag_1_oil  \\\n",
       "0        0                       0                         0        NaN   \n",
       "1        0                       0                         0        NaN   \n",
       "2        0                       0                         0        NaN   \n",
       "3        0                       0                         0        NaN   \n",
       "4        0                       0                         0        NaN   \n",
       "\n",
       "   lag_2_oil  lag_3_oil  lag_4_oil  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(r'novi_datasetovi\\train_test_final.csv',parse_dates=['date'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(static_covs_transform=False,log_transform=False):\n",
    "    lst = []\n",
    "    \n",
    "    filler = MissingValuesFiller(n_jobs=-1)\n",
    "    lst.append(filler)\n",
    "    \n",
    "    if static_covs_transform:\n",
    "        static_covs_transformer = StaticCovariatesTransformer(\n",
    "            transformer_cat=OneHotEncoder(), #one hot encoding static covariates\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        lst.append(static_covs_transformer)\n",
    "\n",
    "    # perform log transformation on sales\n",
    "    if log_transform:\n",
    "        log_transformer = InvertibleMapper(\n",
    "            fn=np.log1p,\n",
    "            inverse_fn=np.expm1,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        lst.append(log_transformer)\n",
    "\n",
    "    # rescale time series\n",
    "    scaler = Scaler()\n",
    "    lst.append(scaler)\n",
    "\n",
    "    pipeline = Pipeline(lst)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_series(static_cols,log_transform=True):    \n",
    "    target_dict = {} #key is family, value is array of time series of sales by stores\n",
    "    pipe_dict = {} #key is family, value is pipeline\n",
    "    id_dict = {} #key is family, value is pair of store and family\n",
    "\n",
    "    for fam in tqdm_notebook(data.family.unique(), desc=\"Extracting target series\"):\n",
    "\n",
    "        #using train and splitting by family\n",
    "        df = data[(data.family.eq(fam)) & (data.date.le('2017-08-15'))] \n",
    "        \n",
    "        # initialize transformation pipeline for target series\n",
    "        pipe = get_pipeline(True, log_transform=log_transform)\n",
    "        \n",
    "        # extract target series together with static covariates\n",
    "        target = TimeSeries.from_group_dataframe(\n",
    "            df=df,\n",
    "            time_col=\"date\",\n",
    "            value_cols=\"sales\",\n",
    "            group_cols=\"store_nbr\",\n",
    "            static_cols=static_cols,\n",
    "        )\n",
    "        \n",
    "        # record identity of each target series\n",
    "        target_id = [{\"store_nbr\": t.static_covariates.store_nbr, \"family\": fam} #pair family store\n",
    "                     for t in target]\n",
    "        id_dict[fam] = target_id\n",
    "\n",
    "        # apply transformations\n",
    "        target = pipe.fit_transform(target)\n",
    "        target_dict[fam] = [t.astype(np.float32) for t in target]\n",
    "\n",
    "        pipe_dict[fam] = pipe[2:]  #without MissingValuesFiller and OHEnc\n",
    "        \n",
    "    return target_dict, pipe_dict, id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e5c3d0317f4dbe8ff73421b80bc413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting target series:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "static_cols = [\"city\", \"state\", \"type\", \"cluster\"]\n",
    "\n",
    "target_dict, pipe_dict, id_dict = get_target_series(static_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariates(\n",
    "    past_cols,\n",
    "    future_cols,\n",
    "):\n",
    "    past_dict = {} #key is family, value is array of time series of transactions by stores\n",
    "    future_dict = {} #key is family, value is array of array of time series of future covariate by stores for all future covariates\n",
    "    \n",
    "    # initialize transformation pipeline for covariates\n",
    "    covs_pipe = get_pipeline()\n",
    "\n",
    "    for fam in tqdm_notebook(data.family.unique(), desc=\"Extracting covariates\"):\n",
    "        # filter data for each model\n",
    "        df = data[data.family.eq(fam)]\n",
    "        \n",
    "        # extract past covariates\n",
    "        past_covs = TimeSeries.from_group_dataframe(\n",
    "            df=df[df.date.le('2017-08-15')],\n",
    "            time_col=\"date\",\n",
    "            value_cols=past_cols,\n",
    "            group_cols=\"store_nbr\",\n",
    "        )\n",
    "        past_covs = [p.with_static_covariates(None) for p in past_covs]\n",
    "        past_covs = covs_pipe.fit_transform(past_covs)\n",
    "        \n",
    "        past_dict[fam] = [p.astype(np.float32) for p in past_covs]\n",
    "\n",
    "        # extract future covariates\n",
    "        future_covs = TimeSeries.from_group_dataframe(\n",
    "            df=df,\n",
    "            time_col=\"date\",\n",
    "            value_cols=future_cols,\n",
    "            group_cols=\"store_nbr\",\n",
    "        )\n",
    "        future_covs = [f.with_static_covariates(None) for f in future_covs]\n",
    "        future_covs = covs_pipe.fit_transform(future_covs)\n",
    "        \n",
    "        future_dict[fam] = [f.astype(np.float32) for f in future_covs]\n",
    "            \n",
    "    return past_dict, future_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dbb5a3e17d4885953014b4ec41484b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting covariates:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# past covariates\n",
    "past_cols = [\"transactions\"]\n",
    "\n",
    "# future covariates\n",
    "future_cols = [\n",
    "    \"work_day\", \"N Batalla de Pichincha\", \"N Carnaval\", \"N Cyber Monday\", \"N Dia de Difuntos\", \"N Dia de la Madre\", \"N Dia del Trabajo\", \"N Futbol\", \"N Independencia de Cuenca\", \"N Independencia de Guayaquil\", \"N Navidad\", \"N Primer dia del ano\", \"N Terremoto Manabi\", \"N Viernes Santo\", \"oil_price\", \"transactions\", \"month\", \"day_of_month\", \"day_of_year\", \"week_of_month\", \"week_of_year\", \"day_of_week\", \"year\", \"is_wknd\", \"quarter\", \"is_month_start\", \"is_month_end\", \"is_quarter_start\", \"is_quarter_end\", \"is_year_start\", \"is_year_end\", \"date_index\", \"season\", \"workday\", \"wageday\", \"day_to_nearest_holiday\", \"day_from_nearest_holiday\"]\n",
    "past_dict, future_dict = get_covariates(past_cols, future_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_CONFIG = {\n",
    "\n",
    "    \"target_dict\": target_dict,\n",
    "    \"pipe_dict\": pipe_dict,\n",
    "    \"id_dict\": id_dict,\n",
    "    \"past_dict\": past_dict,\n",
    "    \"future_dict\": future_dict,\n",
    "    \n",
    "    # time series cross-validation using a rolling forecasting origin\n",
    "    \"forecast_horizon\": 16, # the length of the validation set\n",
    "    \"folds\": 1, # the number of training sets (setting to 1 means the standard train-validation split)\n",
    "    \n",
    "    # the number of previous days to check for zero sales; if all are zero, generate zero forecasts\n",
    "    \"zero_fc_window\": 21,\n",
    "    \n",
    "    \"static_covs\": \"keep_all\",\n",
    "    \"past_covs\": \"keep_all\",\n",
    "    \"future_covs\": \"keep_all\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_dict,\n",
    "        pipe_dict,\n",
    "        id_dict,\n",
    "        past_dict,\n",
    "        future_dict,\n",
    "        forecast_horizon,\n",
    "        folds,\n",
    "        zero_fc_window,\n",
    "        static_covs=None,\n",
    "        past_covs=None,\n",
    "        future_covs=None,\n",
    "    ):\n",
    "        self.target_dict = target_dict.copy()\n",
    "        self.pipe_dict = pipe_dict.copy()\n",
    "        self.id_dict = id_dict.copy()\n",
    "        self.past_dict = past_dict.copy()\n",
    "        self.future_dict = future_dict.copy()\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        self.folds = int(folds)\n",
    "        self.zero_fc_window = zero_fc_window\n",
    "        self.static_covs = static_covs\n",
    "        self.past_covs = past_covs\n",
    "        self.future_covs = future_covs\n",
    "        \n",
    "    \n",
    "    def clip(self, array):\n",
    "        #change negative values to zero\n",
    "        return np.clip(array, a_min=0., a_max=None)\n",
    "    \n",
    "    def train_valid_split(self, target, length):\n",
    "        #length is (self.folds - j) * self.forecast_horizon \n",
    "        train = [t[:-length] for t in target]\n",
    "        valid_end_idx = -length + self.forecast_horizon\n",
    "        if valid_end_idx >= 0:\n",
    "            valid_end_idx = None\n",
    "        valid = [t[-length:valid_end_idx] for t in target]\n",
    "        \n",
    "        return train, valid\n",
    "    \n",
    "    def get_models(self, model_names, model_configs):\n",
    "        models = {\n",
    "            \"lr\": LinearRegressionModel,\n",
    "            \"lgbm\": LightGBMModel,\n",
    "            \"cat\": CatBoostModel,\n",
    "            \"xgb\": XGBModel,\n",
    "        }\n",
    "        assert isinstance(model_names, list) and isinstance(model_configs, list),\\\n",
    "        \"Both the model names and model configurations must be specified in lists.\"\n",
    "        assert all(name in models for name in model_names),\\\n",
    "        f\"Model names '{model_names}' not recognized.\"\n",
    "        assert len(model_names) == len(model_configs),\\\n",
    "        \"The number of model names and the number of model configurations do not match.\"\n",
    "        \n",
    "        if \"xgb\" in model_names:\n",
    "            xgb_idx = np.where(np.array(model_names)==\"xgb\")[0]\n",
    "            for idx in xgb_idx:\n",
    "                # change to histogram-based method for XGBoost to get faster training time\n",
    "                model_configs[idx] = {\"tree_method\": \"hist\", **model_configs[idx]}\n",
    "        \n",
    "        return [models[name](**model_configs[j]) for j, name in enumerate(model_names)]\n",
    "    \n",
    "    def generate_forecasts(self, models, train, pipe, past_covs, future_covs, drop_before):\n",
    "        if drop_before is not None: \n",
    "            date = pd.Timestamp(drop_before) - pd.Timedelta(days=1) \n",
    "            #train without specifed dates\n",
    "            train = [t.drop_before(date) for t in train] \n",
    "        #inputs for a model\n",
    "        inputs = {\n",
    "            \"series\": train,\n",
    "            \"past_covariates\": past_covs,\n",
    "            \"future_covariates\": future_covs,\n",
    "        }\n",
    "\n",
    "        #generates validation dates and all zero values\n",
    "        zero_pred = pd.DataFrame({ \n",
    "            \"date\": pd.date_range(train[0].end_time(), periods=self.forecast_horizon+1)[1:],\n",
    "            \"sales\": np.zeros(self.forecast_horizon),\n",
    "        })\n",
    "        #transforming that df to time series\n",
    "        zero_pred = TimeSeries.from_dataframe( \n",
    "            df=zero_pred,\n",
    "            time_col=\"date\",\n",
    "            value_cols=\"sales\",\n",
    "        )\n",
    "        \n",
    "        pred_list = []\n",
    "        ens_pred = [0 for _ in range(len(train))] #zero for every store \n",
    "        \n",
    "        for m in models:\n",
    "            # fit training data to model\n",
    "            m.fit(**inputs)\n",
    "\n",
    "            # generate forecasts\n",
    "            pred = m.predict(n=self.forecast_horizon, **inputs)\n",
    "            #apply inverse transformations\n",
    "            pred = pipe.inverse_transform(pred)\n",
    "\n",
    "            for j in range(len(train)):\n",
    "                #if there is all zeros in j time series in the last specifed period of time predict zeros\n",
    "                if train[j][-self.zero_fc_window:].values().sum() == 0:\n",
    "                    pred[j] = zero_pred\n",
    "            \n",
    "            # clip negative forecasts to 0s\n",
    "            pred = [p.map(self.clip) for p in pred]\n",
    "            pred_list.append(pred)\n",
    "            \n",
    "            # ensemble averaging\n",
    "            for j in range(len(ens_pred)): #54\n",
    "                ens_pred[j] += pred[j] / len(models) \n",
    "\n",
    "        return pred_list, ens_pred\n",
    "    \n",
    "    def metric(self, valid, pred):\n",
    "\n",
    "        valid_df = pd.concat([ts.pd_dataframe() for ts in valid], axis=1)\n",
    "        pred_df = pd.concat([ts.pd_dataframe() for ts in pred], axis=1)\n",
    "\n",
    "        # calculate RMSLE for each pair of valid and predicted values\n",
    "        rmsle_values = [np.sqrt(mean_squared_log_error(valid_df[col], pred_df[col],squared=False)) for col in valid_df.columns]\n",
    "\n",
    "        # calculate the mean of RMSLE values of all series of that family\n",
    "        mean_rmsle = np.mean(rmsle_values)\n",
    "\n",
    "        return mean_rmsle\n",
    "    \n",
    "    def validate(self, model_names, model_configs, drop_before=None):\n",
    "        # helper value to align printed text below\n",
    "        longest_len = len(max(self.target_dict.keys(), key=len)) #33 kao broj prodavnica\n",
    "        \n",
    "        # store metric values for each model\n",
    "        model_metrics_history = []\n",
    "        ens_metric_history = []\n",
    "        \n",
    "        for fam in tqdm_notebook(self.target_dict, desc=\"Performing validation\"):\n",
    "            target = self.target_dict[fam]\n",
    "            pipe = self.pipe_dict[fam]\n",
    "            past_covs = self.past_dict[fam]\n",
    "            future_covs = self.future_dict[fam]\n",
    "            \n",
    "            # record average metric value over all folds\n",
    "            model_metrics = []\n",
    "            ens_metric = 0\n",
    "            \n",
    "            for j in range(self.folds):    #folds=1\n",
    "                # perform train-validation split and apply transformations\n",
    "                length = (self.folds - j) * self.forecast_horizon #16\n",
    "                train, valid = self.train_valid_split(target, length) \n",
    "                valid = pipe.inverse_transform(valid) \n",
    "\n",
    "                # generate forecasts and compute metric\n",
    "                models = self.get_models(model_names, model_configs)\n",
    "                pred_list, ens_pred = self.generate_forecasts(models, train, pipe, past_covs, future_covs, drop_before) ################################################################\n",
    "                metric_list = [self.metric(valid, pred) / self.folds for pred in pred_list]\n",
    "                model_metrics.append(metric_list)\n",
    "                if len(models) > 1:\n",
    "                    ens_metric_fold = self.metric(valid, ens_pred) / self.folds\n",
    "                    ens_metric += ens_metric_fold\n",
    "                \n",
    "            # store final metric value for each model\n",
    "            model_metrics = np.sum(model_metrics, axis=0)\n",
    "            model_metrics_history.append(model_metrics)\n",
    "            ens_metric_history.append(ens_metric)\n",
    "            \n",
    "            # print metric value for each family\n",
    "            print(\n",
    "                fam,\n",
    "                \" \" * (longest_len - len(fam)),\n",
    "                \" | \",\n",
    "                \" - \".join([f\"{model}: {metric:.5f}\" for model, metric in zip(model_names, model_metrics)]),\n",
    "                f\" - ens: {ens_metric:.5f}\" if len(models) > 1 else \"\",\n",
    "                sep=\"\",\n",
    "            )\n",
    "            \n",
    "        # print overall metric value\n",
    "        print(\n",
    "            \"Average RMSLE | \"\n",
    "            + \" - \".join([f\"{model}: {metric:.5f}\" \n",
    "                          for model, metric in zip(model_names, np.mean(model_metrics_history, axis=0))])\n",
    "            + (f\" - ens: {np.mean(ens_metric_history):.5f}\" if len(models) > 1 else \"\"),\n",
    "        )\n",
    "        \n",
    "    def ensemble_predict(self, model_names, model_configs, drop_before=None):        \n",
    "        forecasts = []\n",
    "        for fam in tqdm_notebook(self.target_dict.keys(), desc=\"Generating forecasts\"):\n",
    "            target = self.target_dict[fam]\n",
    "            pipe = self.pipe_dict[fam]\n",
    "            target_id = self.id_dict[fam]\n",
    "            past_covs = self.past_dict[fam]\n",
    "            future_covs = self.future_dict[fam]\n",
    "            \n",
    "            models = self.get_models(model_names, model_configs)\n",
    "            pred_list, ens_pred = self.generate_forecasts(models, target, pipe, past_covs, future_covs, drop_before)\n",
    "            ens_pred = [p.pd_dataframe().assign(store_number=i['store_nbr']['sales'], family=i['family']) for p, i in zip(ens_pred, target_id)]\n",
    "            ens_pred = pd.concat(ens_pred, axis=0)\n",
    "            forecasts.append(ens_pred)\n",
    "            \n",
    "        # combine all forecasts into one dataframe\n",
    "        forecasts = pd.concat(forecasts, axis=0)\n",
    "        forecasts = forecasts.rename_axis(None, axis=1).reset_index(names=\"date\")\n",
    "        \n",
    "        return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(**TRAINER_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"random_state\": 0,\n",
    "    \n",
    "    # the number of lag values of the target series\n",
    "    \"lags\": 63,\n",
    "    \n",
    "    # the number of lag values of the past covariates\n",
    "    \"lags_past_covariates\": list(range(-16, -23, -1)),\n",
    "    \n",
    "    # the number of (past, future-1) lag values of the future covariates\n",
    "    \"lags_future_covariates\": (14, 1),\n",
    "    \n",
    "    # the number of days ahead that the model is forecasting given today's input data\n",
    "    \"output_chunk_length\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5cc61afa474827bd5d7639a23e1d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Performing validation:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTOMOTIVE                 | lr: 0.70056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BABY CARE                  | lr: 0.42990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEAUTY                     | lr: 0.71331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEVERAGES                  | lr: 0.46407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOKS                      | lr: 0.16987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BREAD/BAKERY               | lr: 0.39786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CELEBRATION                | lr: 0.74175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANING                   | lr: 0.53351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAIRY                      | lr: 0.36195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELI                       | lr: 0.38772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EGGS                       | lr: 0.50494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROZEN FOODS               | lr: 0.50027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROCERY I                  | lr: 0.37276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROCERY II                 | lr: 0.74678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HARDWARE                   | lr: 0.71469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME AND KITCHEN I         | lr: 0.68501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME AND KITCHEN II        | lr: 0.66352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME APPLIANCES            | lr: 0.55467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME CARE                  | lr: 0.58896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LADIESWEAR                 | lr: 0.65428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAWN AND GARDEN            | lr: 0.59625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINGERIE                   | lr: 0.78433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIQUOR,WINE,BEER           | lr: 0.71431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAGAZINES                  | lr: 0.70919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEATS                      | lr: 0.44241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONAL CARE              | lr: 0.43915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PET SUPPLIES               | lr: 0.67730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLAYERS AND ELECTRONICS    | lr: 0.68155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POULTRY                    | lr: 0.43704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARED FOODS             | lr: 0.50217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRODUCE                    | lr: 0.59261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCHOOL AND OFFICE SUPPLIES | lr: 1.00870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEAFOOD                    | lr: 0.66672\n",
      "Average RMSLE | lr: 0.57994\n"
     ]
    }
   ],
   "source": [
    "trainer.validate([\"lr\"], [BASE_CONFIG], drop_before=\"2014-06-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34b59cf18ef4b3687110e32b4849559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating forecasts:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n",
      "`predict()` was called with `n > output_chunk_length`: using auto-regression to forecast the values after `output_chunk_length` points. The model will access `(n - output_chunk_length)` future values of your `past_covariates` (relative to the first predicted time step). To hide this warning, set `show_warnings=False`.\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.ensemble_predict(\n",
    "    model_names=[\"lr\"], \n",
    "    model_configs=[BASE_CONFIG],\n",
    "    drop_before=\"2014-06-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28507</th>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>0.166696</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>2017-08-28</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28509</th>\n",
       "      <td>2017-08-29</td>\n",
       "      <td>0.302703</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28510</th>\n",
       "      <td>2017-08-30</td>\n",
       "      <td>0.075346</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28511</th>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>0.149236</td>\n",
       "      <td>54</td>\n",
       "      <td>SEAFOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     sales  store_nbr   family\n",
       "28507 2017-08-27  0.166696         54  SEAFOOD\n",
       "28508 2017-08-28  0.000000         54  SEAFOOD\n",
       "28509 2017-08-29  0.302703         54  SEAFOOD\n",
       "28510 2017-08-30  0.075346         54  SEAFOOD\n",
       "28511 2017-08-31  0.149236         54  SEAFOOD"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions = predictions.copy()\n",
    "final_predictions['store_number']=final_predictions['store_number'].astype(int)\n",
    "final_predictions.rename(columns={'store_number': 'store_nbr'}, inplace=True)\n",
    "final_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=data[data['date']>= '2017-08-16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>work_day</th>\n",
       "      <th>N Batalla de Pichincha</th>\n",
       "      <th>N Carnaval</th>\n",
       "      <th>N Cyber Monday</th>\n",
       "      <th>N Dia de Difuntos</th>\n",
       "      <th>N Dia de la Madre</th>\n",
       "      <th>N Dia del Trabajo</th>\n",
       "      <th>N Futbol</th>\n",
       "      <th>N Independencia de Cuenca</th>\n",
       "      <th>N Independencia de Guayaquil</th>\n",
       "      <th>N Navidad</th>\n",
       "      <th>N Primer dia del ano</th>\n",
       "      <th>N Terremoto Manabi</th>\n",
       "      <th>N Viernes Santo</th>\n",
       "      <th>oil_price</th>\n",
       "      <th>transactions</th>\n",
       "      <th>lag_16_sales</th>\n",
       "      <th>lag_17_sales</th>\n",
       "      <th>lag_18_sales</th>\n",
       "      <th>lag_19_sales</th>\n",
       "      <th>lag_20_sales</th>\n",
       "      <th>lag_30_sales</th>\n",
       "      <th>lag_365_sales</th>\n",
       "      <th>lag_730_sales</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>week_of_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>year</th>\n",
       "      <th>is_wknd</th>\n",
       "      <th>quarter</th>\n",
       "      <th>is_month_start</th>\n",
       "      <th>is_month_end</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>date_index</th>\n",
       "      <th>season</th>\n",
       "      <th>workday</th>\n",
       "      <th>wageday</th>\n",
       "      <th>day_to_nearest_holiday</th>\n",
       "      <th>day_from_nearest_holiday</th>\n",
       "      <th>lag_1_oil</th>\n",
       "      <th>lag_2_oil</th>\n",
       "      <th>lag_3_oil</th>\n",
       "      <th>lag_4_oil</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3008016</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>47.57</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.996667</td>\n",
       "      <td>48.403333</td>\n",
       "      <td>3000888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008017</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>47.57</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.996667</td>\n",
       "      <td>48.403333</td>\n",
       "      <td>3000889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008018</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>47.57</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.996667</td>\n",
       "      <td>48.403333</td>\n",
       "      <td>3000890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008019</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2414.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>2161.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2381.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>47.57</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.996667</td>\n",
       "      <td>48.403333</td>\n",
       "      <td>3000891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3008020</th>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>228</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1688</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "      <td>47.57</td>\n",
       "      <td>47.59</td>\n",
       "      <td>47.996667</td>\n",
       "      <td>48.403333</td>\n",
       "      <td>3000892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date  store_nbr      family  sales  onpromotion   city  \\\n",
       "3008016 2017-08-16          1  AUTOMOTIVE    NaN          0.0  Quito   \n",
       "3008017 2017-08-16          1   BABY CARE    NaN          0.0  Quito   \n",
       "3008018 2017-08-16          1      BEAUTY    NaN          2.0  Quito   \n",
       "3008019 2017-08-16          1   BEVERAGES    NaN         20.0  Quito   \n",
       "3008020 2017-08-16          1       BOOKS    NaN          0.0  Quito   \n",
       "\n",
       "             state type  cluster  work_day  N Batalla de Pichincha  \\\n",
       "3008016  Pichincha    D       13         0                       0   \n",
       "3008017  Pichincha    D       13         0                       0   \n",
       "3008018  Pichincha    D       13         0                       0   \n",
       "3008019  Pichincha    D       13         0                       0   \n",
       "3008020  Pichincha    D       13         0                       0   \n",
       "\n",
       "         N Carnaval  N Cyber Monday  N Dia de Difuntos  N Dia de la Madre  \\\n",
       "3008016           0               0                  0                  0   \n",
       "3008017           0               0                  0                  0   \n",
       "3008018           0               0                  0                  0   \n",
       "3008019           0               0                  0                  0   \n",
       "3008020           0               0                  0                  0   \n",
       "\n",
       "         N Dia del Trabajo  N Futbol  N Independencia de Cuenca  \\\n",
       "3008016                  0         0                          0   \n",
       "3008017                  0         0                          0   \n",
       "3008018                  0         0                          0   \n",
       "3008019                  0         0                          0   \n",
       "3008020                  0         0                          0   \n",
       "\n",
       "         N Independencia de Guayaquil  N Navidad  N Primer dia del ano  \\\n",
       "3008016                             0          0                     0   \n",
       "3008017                             0          0                     0   \n",
       "3008018                             0          0                     0   \n",
       "3008019                             0          0                     0   \n",
       "3008020                             0          0                     0   \n",
       "\n",
       "         N Terremoto Manabi  N Viernes Santo  oil_price  transactions  \\\n",
       "3008016                   0                0       46.8           0.0   \n",
       "3008017                   0                0       46.8           0.0   \n",
       "3008018                   0                0       46.8           0.0   \n",
       "3008019                   0                0       46.8           0.0   \n",
       "3008020                   0                0       46.8           0.0   \n",
       "\n",
       "         lag_16_sales  lag_17_sales  lag_18_sales  lag_19_sales  lag_20_sales  \\\n",
       "3008016           8.0           1.0           4.0           7.0           5.0   \n",
       "3008017           0.0           0.0           0.0           0.0           0.0   \n",
       "3008018           3.0           2.0           3.0           2.0           1.0   \n",
       "3008019        2414.0        1212.0        2161.0        2358.0        2002.0   \n",
       "3008020           1.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "         lag_30_sales  lag_365_sales  lag_730_sales  month  day_of_month  \\\n",
       "3008016           2.0            5.0            0.0      8            16   \n",
       "3008017           0.0            0.0            0.0      8            16   \n",
       "3008018           5.0            5.0            2.0      8            16   \n",
       "3008019        2381.0         2010.0         2194.0      8            16   \n",
       "3008020           1.0            0.0            0.0      8            16   \n",
       "\n",
       "         day_of_year  week_of_month  week_of_year  day_of_week  year  is_wknd  \\\n",
       "3008016          228              3            33            3  2017        0   \n",
       "3008017          228              3            33            3  2017        0   \n",
       "3008018          228              3            33            3  2017        0   \n",
       "3008019          228              3            33            3  2017        0   \n",
       "3008020          228              3            33            3  2017        0   \n",
       "\n",
       "         quarter  is_month_start  is_month_end  is_quarter_start  \\\n",
       "3008016        3               0             0                 0   \n",
       "3008017        3               0             0                 0   \n",
       "3008018        3               0             0                 0   \n",
       "3008019        3               0             0                 0   \n",
       "3008020        3               0             0                 0   \n",
       "\n",
       "         is_quarter_end  is_year_start  is_year_end  date_index  season  \\\n",
       "3008016               0              0            0        1688       2   \n",
       "3008017               0              0            0        1688       2   \n",
       "3008018               0              0            0        1688       2   \n",
       "3008019               0              0            0        1688       2   \n",
       "3008020               0              0            0        1688       2   \n",
       "\n",
       "         workday  wageday  day_to_nearest_holiday  day_from_nearest_holiday  \\\n",
       "3008016        1        0                       5                        54   \n",
       "3008017        1        0                       5                        54   \n",
       "3008018        1        0                       5                        54   \n",
       "3008019        1        0                       5                        54   \n",
       "3008020        1        0                       5                        54   \n",
       "\n",
       "         lag_1_oil  lag_2_oil  lag_3_oil  lag_4_oil       id  \n",
       "3008016      47.57      47.59  47.996667  48.403333  3000888  \n",
       "3008017      47.57      47.59  47.996667  48.403333  3000889  \n",
       "3008018      47.57      47.59  47.996667  48.403333  3000890  \n",
       "3008019      47.57      47.59  47.996667  48.403333  3000891  \n",
       "3008020      47.57      47.59  47.996667  48.403333  3000892  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=test.copy()\n",
    "start_id = 3000888\n",
    "end_id = start_id + len(test)\n",
    "ids = range(start_id, end_id)\n",
    "\n",
    "test['id'] = ids\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>0.786582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>1.110778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>262.677826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       sales\n",
       "0  3000888    0.786582\n",
       "1  3000889    0.000000\n",
       "2  3000890    1.110778\n",
       "3  3000891  262.677826\n",
       "4  3000892    0.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = final_predictions.copy()\n",
    "submission = test.merge(\n",
    "    final, on=[\"date\", \"store_nbr\", \"family\"], how=\"left\",\n",
    ")\n",
    "submission=submission.reset_index()\n",
    "submission=submission[['id','sales_y']]\n",
    "submission.rename(columns={'sales_y': 'sales'}, inplace=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv(\"submission2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
